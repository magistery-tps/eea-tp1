---
title: |
    | Maestría en Explotación de datos y Descubrimiento de conocimiento
    |
    |
    | Materia: Enfoque Estadistico del Aprendizaje
    | Trabajo práctico 1: Regresion Lineal
author: "Adrian Norberto Marino"
date: "2021/09/19"
fig_width: 3 
fig_height: 3 
output:
  html_document:
    highlight: pygments
    theme: sandstone
    toc: yes
    df_print: paged
    includes:
      before_body: ./header.html
      after_body: ./footer.html
  html_notebook:
    toc: yes
    toc_float: yes
    df_print: paged
editor_options: 
  markdown: 
    wrap: 100
---

## 2. Modelo inicial

### 2.1. Se plantea la siguiente primera alternativa para modelar el peso:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * diasActividadFisicaSemanal + \beta5 * consumoDiarioAlcohol$

Primero se cargan las librerías necesarias:

```{r message=FALSE, warning=FALSE}
options(warn=-1)
rm(list=ls())
gc()
options(warn=-2)
```

```{r message=FALSE, warning=FALSE}
# install.packages("pacman") -- Descomentar par instalar pacman
library(pacman)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
import('../src/preprocessing.R')
import('../src/model.R')
import('../src/plot.R')
```

A continuación se carga los conjuntos de entrenamiento y test. también se resumen los valores de las
variables categóricas y se excluyen las observaciones con valores faltantes, ya que son muy pocas
con respecto al total.

```{r message=FALSE, warning=FALSE}
train_set <- load_train_set() %>% 
  preprocess() %>% 
  shorten_values() %>%
  process_missings()

test_set <- load_test_set() %>% 
  preprocess() %>% 
  shorten_values() %>% 
  process_missings()
```

```{r}
glimpse(train_set)
```

Se fija la semilla y se validan las proporciones de los conjuntos de entrenamiento y test:

```{r}
set.seed(25)
show_train_test_props(train_set, test_set)
```

**Modelo 1**

Se plantea el primer modelo lineal:

```{r}
model_1 <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set
)
```

### 2.2. ¿Cuál es la interpretación de cada uno de los coeficientes estimados?

Veamos a continuación un resumen de los coeficiente del **modelo 1**:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_1)
```

Al analizar cada coeficiente se encuentra que:

-   $\hat{\beta_0}$ (Ordenada al origen) de valor -68.92 Kg, es el peso esperado o promedio de un
    individuo de genero femenino que tiene cero altura, edad, actividad física y consumo diario de
    alcohol. Esto no es interpretable, ya que una persona tiene que tener una altura superior a cero
    y no puede tener un peso negativo, pero si podría no realizar actividad física ni consumir
    alcohol.

-   El coeficiente $\hat{\beta_1}$ de valor 653 gramos, corresponde a la altura del individuo. Este
    coeficiente indica que dada una edad, genero, consumo de alcohol diario y días de actividad
    física semanal fijos, cada incremento en 1 cm adicional en la altura del individuo implica un
    aumento de su peso esperado o promedio de 653 gramos.

-   El coeficiente $\hat{\beta_2}$ de valor 1.378 kg, corresponde a la edad del individuo. Este
    coeficiente indica que dada una altura, genero, días de actividad física y consumo de alcohol
    diario fijos, cada vez que el individuo cumple un año su peso esperado o promedio aumenta en
    1.378 kg.

-   El coeficiente $\hat{\beta_3}$ de valor 1.224 kg, corresponde a los individuos de genero
    masculinos. Este coeficiente indica que dada una altura, edad, consumo de alcohol diario y días
    de actividad física semanal fijos, el peso promedio o esperado para el genero masculino es 1.224
    kg mayor al peso femenino (categoría basal). Por otro lado, el coeficientes no indica cunado mas
    alto es el peso del genero masculino respecto del femenino al fijar los demás coeficientes.

-   El coeficiente $\hat{\beta_4}$ de valor 99.1 gramos, corresponde a los días de actividad física
    semanal que realiza el individuo. Este coeficiente indica que dada una altura, edad, genero y
    consumo de alcohol diario, cada vez que un individuo realiza un día mas de actividad física
    semanal su peso esperado o promedio disminuye en 99.1 gramos.

-   El coeficiente $\hat{\beta_5}$ de valor -8 gramos, corresponde al nivel de consumo diario de
    alcohol del individuo. Este coeficiente indica que dada una altura, edad, genero y días de
    actividad física semanal fijos, cada vez que el individuo consume un trago de alcohol su peso
    esperado o promedio disminuye en 8 gramos. A simple vista podrá no llegar a tener sentido, ya
    que a mayor consumo de alcohol el peso debería aumentar, ya sea por el peso del propio liquido
    como el peso equivalente en grasas. Entiendo que puede tener un relación con los rangos de
    edades de los individuos que mas consumen alcohol (12 q 17 años), ya que estos se encuentran en
    pleno crecimiento.

### 2.3. ¿Son significativos los coeficientes?

Para determina si los coeficientes son aptos para explicar el peso de un individuo se realiza un
${T}$ test para cada coeficiente en el cual se evalúan las siguientes hipótesis:

-   ${H_0: \beta_i = 0}$
-   ${H_1: \beta_i \neq 0}$

Si ${\beta_i \neq 0}$ podemos decir que existe una diferencia estadisticamente significativas del
cero para coeficiente ${\beta_i}$, y por lo tanto el coeficiente ${\beta_i}$ explicar la variable
${y}$ (Peso en nuestro caso).

Luego analizando la salida de **coefficients_summary** concluimos que:

-   Los coeficientes correspondientes al acategoria basal ${\beta_1}$(Genero femenino),
    altura(${\beta_1}$), edad(${\beta_2}$) y genero masculino (${\beta_3}$) tienen $p-valor < 0.05$.
    Por lo tanto, se rechaza la hipótesis nula y resultan estadistitamente significativos para
    explicar el peso. Por otro lado, se puede apreciar que los intervalos de confianza del 95% no
    incluyen al cero.
-   Lo contrario sucede con días de actividad física semanal(${\beta_4}$) y consumo de alcohol
    diario (${\beta_5}$), dado que ambos no rechazar la hipótesis nula ($p-valor > 0.05$) y por lo
    tanto no existe una diferencia significativa del cero. Finalmente, no hay evidencia
    estadistitamente significativas de que estos coeficientes expliquen al peso.

### 2.4. ¿El modelo resulta significativo para explicar el peso?

Para determinar si es modelo es significativo para explicar el peso de un individuo se realiza un
$F$ test con las siguientes hipótesis:

-   $H_0: β_1 = β_2 = · · · = β_{p−1} = 0$
-   $H_1:$ Por lo menos un $β_k$ ($k = 1, 2,..., p−1$) es distinto de 0.

Donde: \* $H_0$ afirma que no hay vinculo entre la variable ${y}$(Peso) y las variables regresoras.
\* $H_1$ afirma que al menos una de las variables regresoras sirve para predecir la variable ${y}$
(Peso).

Veamos los resultados el $F$ test:

```{r}
glance(model_1)
```

Podemos apreciar que el $p-valor < 0.05$ e igual a 0. Con mucha certeza podemos decir que al menos
una de las variables regresoras permite explicar el peso. Esto concuerda con los resultados de los
$T$ test para las los coeficientes correspondientes a altura, edad y genero femenino(basa) y
masculino).

### 2.5. ¿Qué porcentaje de la variabilidad explica el modelo?

Según el valor de $R^2$ ajustado (**adj.r.squared**), este modelo llega a explica el 35% de la
variabilidad del dataset de entrenamiento, lo cual no es un valor bajo pero tampoco es despreciable.

### 2.6. ¿Que sucede si poner al genero masculino como variable basal?

```{r}
train_set_genero <- data.frame(train_set) 
train_set_genero$genero <- factor(
  train_set_genero$genero,
  levels=c('Masculino', 'Femenino'), 
  ordered=FALSE
)
table(train_set_genero$genero)
```

```{r}
model_genero <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set_genero
)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_genero)
```

```{r}
glance(model_genero)
```

**Observaciones**

-   En este caso, cambia el coeficiente $\beta_0$ para la categoría basal, manteniéndose los demás
    coeficientes.
-   Siguen siendo significativos los mismo coeficientes. La unica diferencia es que $\beta_0$(basal)
    representa al genero masculino y $\beta_3$ al femenino.
-   Se mantiene la significatividad global del modelo y el mismo $R^2$.
-   Como ultimo, cabe aclarar que al cambiar la categoría basar cambian las interpretaciones del
    modelo.

## 3. Modelo categóricas

### 3.1. Se sugiere probar un modelo que incorpore el consumo semanal de snacks y una interacción entre el género y la edad, en lugar de actividad física y consumo de alcohol. Además se pide explicitamente que la categoría "No comí comida salada o snacks en los últimos 7 días" de la variable **consumo_semanal_snacks** se encuentre como nivel/categoría basal.

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

Primero validamos que las primeras categorías en cada variable de tipo factor sean las correctas, ya
que esta sera la que el modelo defina como categoría basal:

```{r}
table(train_set$consumo_semanal_snacks)
table(train_set$genero)
```

Se puede apreciar que la primeras categorías corresponden a 0 consumo de snacks semanal y genero
femenino. Por otro lado la categoría genero se encuentra balanceada.

**Modelo 2**

Definimos el nuevo modelo:

```{r}
model_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set
)
```

### 3.2. ¿Cuál es la interpretación de los coeficientes estimados para las categorías de consumo_semanal_snacks y genero \* edad? ¿Son significativas?

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_2)
```

Si interpretamos los coeficientes que son significativos para el $T$ test:

1.  Coeficiente correspondiente al **consumo_semanal_snacks\<=3**:

Si fijamos los coeficientes correspondientes a la altura, edad, generoMasculino y
generoMasculino\*edad; el peso promedio o esperado de un individuo de consume snacks hasta 3 veces
por semana es 1.43 kg menor que aquellos que no consumen snacks.

2.  Sucede algo similar con las categorias **consumo_semanal_snacks4-6** y
    **consumo_semanal_snacks>=28** donde:

-   El peso para un individio que consume de 4 a 6 veces por semana es 2.25 kg menor que aquellos
    con no consumen snacks.
-   El peso para un individio que consume 28 veces a mas por semana es 2.6 kg menor que aquellos con
    no consumen snacks.

3.  Coeficiente correspondiente al **edad \* genero**:

Dado el modelo original:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \ \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

y sabiendo que el genero femenino toma el valor 0 y masculino 1. Si reemplazamos estos valores en el
modelo original encontramos que:

$E_f(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_4 * consumoSemanalSnacks$

El genero femenino tiene la ordenada $\beta0$ y las pendientes determinada por $\beta_1$, $\beta_2$
y $\beta_4$.

$E_m(peso) = (\beta_0 + \beta_3) + \beta_1 \* altura + (\beta_2 + \beta_2,3) * edad + \ \beta_4 * consumoSemanalSnacks$

El genero masculino tiene una ordenada que es la suma de la ordenada del genero femenino $\beta_0$
mas $\beta_3$. Luego cambia la pendiente $\beta_2$ de la edad, a la cual se le suma $\beta_2,3$

Luego, sabiendo que solo cambian los coeficientes correspondientes al genero y edad, si mantenemos
contantes los demás coeficientes obtenemos:

-   $E_f(peso) = \beta_0 + \beta_2 * edad + cte$
-   $E_m(peso) = (\beta_0 + \beta_3) + (\beta_2 + \beta_2,3) * edad$

Ahora reemplazamos por los coeficientes por lo valores que encontró el modelo:

-   Femenino:

    -   $E_f(peso) = -65.56456109 + 1.22539002 edad + cte$

-   Masculino:

    1.  $E_m(peso) = (-65.56456109 + -4.60464631) + (1.22539002 + 0.38927567) * edad + cte$
    2.  $E_m(peso) =-70.1692074 + 1.61466569 * edad + cte$

Finalmente, graficamos ambas rectas definiendo la $cte$ con un valor que de pesos positivos para
tener una gráfica consistente:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
cte = 100

train_set %>% 
  mutate(
    peso = ifelse(
      genero=='Femenino', 
      (-65.56456109 + 1.22539002 * edad) + cte,
      (-70.1692074 + 1.61466569 * edad) + cte
    ) 
  ) %>%
  ggplot(aes(x = edad, y = peso, colour=genero)) +
  geom_line() +
  ylab('Peso') +
  xlab('Edad')
```

Finalmente, se puede apreciar que las ordenadas de ambos géneros son distintas, donde el genero
femenino inicia desde un peso menor al masculino. Luego si variamos únicamente la edad, se aprecia
que el peso del genero masculino es mayor al femenino para la misma edad en todo los casos. Esto se
debe a que la resta correspondiente al genero masculina esta por arriba de la resta correspondiente
al genero femenino.

### 3.3. ¿Qué porcentaje de la variabilidad explica el modelo? En caso de detectar que existen categorías no significativas de la variable consumo_semanal_snacks evaluar si la variable es significativa en su conjunto y, en caso afirmativo, proponer una redefinición de las mismas que permita obtener una mayor proporción de categorías significativas individualmente. Luego, analizar si existen cambios en la variabilidad explicada por el modelo.

Viendo el resultado de **coefficients_summary** se aprecia que las siguientes categorías de
**consumo_semanal_snacks** no son significativas:

-   2 veces al día (14 veces/semana)
-   4 a 6 veces durante los últimos 7 (4 a 6 veces semana)
-   3 veces al día (21 veces/semana)

Pero si son significativos los extremos:

-   De 1 a 3 veces/semana
-   De 28 o mas veces/semana

A continuación se realiza un $F$ test para evaluar la significatividad conjunta de las categóricas
de la variable **consumo_semanal_snacks** para explicar el peso.

El $F$ test también llamando ANOVA (Análisis de la varianza) se realiza para probar la
significatividad conjunta de todos los valores de una variable categórica.

Las hipótesis son las siguientes:

-   $H_0: β_q = β_{q+1} = · · · = β_{p−1} = 0$
-   $H_1:$ por lo menos uno de los $β_k$ (con $k$ entre $q$ y $p−1$) es tal que $β_k \neq 0$.

Luego si todos los coeficientes asociados a los valores de variable categórica son cero, se rechaza
la hipótesis nula y por lo tanto la variable no es significartiva para explicar el peso en nuestro
caso.

A continuación veremos el p-valor resultado de aplicar $F$ test para cada variable del modelo:

```{r}
anova_summary(model_2)
```

Podemos apreciar que el $p-value < 0.005$ para la variable **consumo_semanal_snacks**. Por lo tanto
se rechaza la hipótesis nula y podemos decir en su conjunto resulta estadísticamente significativa
para explicar el peso. Luego, como la variable **consumo_semanal_snacks** es significativa vale la
pena re-definirla. Por otro lado, la combinación de variables genero-edad no es estadísticamente
significativa para explicar el peso, pero si lo es el genero en forma separada. Finalmente, como ya
vimos en pasos anteriores, edad y altura son significativas.

**Modelo 2: Redefinición 1**

Dado que no todas las categorías de la variable **consumo_semanal_snacks** sin significativas a
continuación se propone una re-definición de sus categorías que hace que todas ellas sean
significativas para el **modelo 2**.

```{r}
train_set_snack_1 <- train_set %>% mutate(consumo_semanal_snacks = case_when(
  consumo_semanal_snacks %in% c('<=3', '4-6' , '7')  ~ '<=7',
  consumo_semanal_snacks %in% c('14', '21', '>=28')  ~ '>=14',
  TRUE ~ as.character(consumo_semanal_snacks)
))
train_set_snack_1$consumo_semanal_snacks <- factor(
  train_set_snack_1$consumo_semanal_snacks,
  levels=c('0', '<=7', '>=14'),
  ordered=FALSE
)

test_set_snack_1 <- test_set %>% mutate(consumo_semanal_snacks = case_when(
  consumo_semanal_snacks %in% c('<=3', '4-6' , '7')  ~ '<=7',
  consumo_semanal_snacks %in% c('14', '21', '>=28')  ~ '>=14',
  TRUE ~ as.character(consumo_semanal_snacks)
))

table(train_set_snack_1$consumo_semanal_snacks)
table(test_set_snack_1$consumo_semanal_snacks) 
```

```{r}
model_2_redefinicion_1 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_1
)

coefficients_summary(model_2_redefinicion_1)
anova_summary(model_2_redefinicion_1)
glance(model_2_redefinicion_1)
```

**Modelo 2: Redefinición 2**

En este caso se propone calcular la media del ratio **altura/edad** para cada categoría de la
variables **consumo_semanal_snacks**. Luego calculamos los cuantiles de esta nueva distribución y
los utilizamos para crear una nueva categorización: los individuos que tenga un ratio menor al
cuantil 2 tendran el valor **Bajo** y **Alto** en caso contrario. Se intento llevar a mas niveles
pero el test $T$ no daba significativo para todos los coeficientes del **modelo 2**.

1.  Definimos la districión altura/edad por categoria de **consumo_semanal_snacks**:

```{r fig.height=2, fig.width=4, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>% 
  mutate(alt_edad_ratio = round(altura/edad, 0))

avg_train_set_snack_2 <- train_set_snack_2 %>% 
   group_by(consumo_semanal_snacks) %>% 
   summarise(avg_alt_edad_ratio = mean(alt_edad_ratio))

ggplot(data = avg_train_set_snack_2, aes(x = avg_alt_edad_ratio)) + 
  geom_boxplot(alpha = 0.75, fill="blue") +
  theme_bw()
```

Se los siguientes cuantiles utilizaremos el cuantil 2(50%):

```{r}
quantiles_avg_alt_edad_ratio <- quantile(avg_train_set_snack_2$avg_alt_edad_ratio)
quantiles_avg_alt_edad_ratio
```

2.  Creamos un dataset intermedio donde estan mapeadas las categorias originales vs las nuevas:

```{r}
q2 <- quantiles_avg_alt_edad_ratio[3]

snack_level_mapping <- avg_train_set_snack_2 %>% 
  mutate(level = case_when(
    avg_alt_edad_ratio < q2  ~ 'Bajo',
    avg_alt_edad_ratio >=  q2 ~ 'Alto'
  )) %>% select(consumo_semanal_snacks, level)

snack_level_mapping %>%
  arrange(consumo_semanal_snacks)
```

3.  Creamos nuevos dataset de train/test con la nueva definición de la variable
    **consumo_semanal_snacks**:

```{r fig.height=4, fig.width=5, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)

test_set_snack_2 <- test_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)
```

```{r warning=FALSE}
train_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()

test_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()
```

4.  Evaluamos el nuevo train_set con el **modelo 2**:

```{r}
model_2_redefinicion_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_2
)

coefficients_summary(model_2_redefinicion_2)
anova_summary(model_2_redefinicion_2)
glance(model_2_redefinicion_2)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
models <- list(
  'Modelo 1' = model_1, 
  'Modelo 2' = model_2, 
  'Modelo 2 - Re-definición 1' = model_2_redefinicion_1, 
  'Modelo 2 - Re-definición 2' = model_2_redefinicion_2
)

models %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

**Conclusión**: Ambos modelos son significativos para explicar el peso. El modelo **Modelo 2 -
Re-definición 1** es mas explicativo, ya que $R^2$ ajustado es mayor. Finamente, ambos modelos son
meno explicativos que el modelo original(**Modelo 2**).

## 4. Modelos propios y evaluación

### 4.1. Realizar 2 modelos lineales múltiples adicionales y explicar breve-mente la lógica detrás de los mismos (se valorará la creación y/o inclusión de variables nuevas). 

Al continuación se define 2 modelos.

**Modelo 3**

Para este primer modelo se tiene en cuenta las siguintes variables:

* Altura: Ya que la altura influye en el peso del individio diretamente.
* Genero: No tiene un relacion directa pero lo individios mascuklino tienen a tener mas altura y por ende mayor peso.
* consumo_semanal_snacks y consumo_semanal_comida_grasa: Puede considerarse que estas variables afectan en gran media al aumento de peso.
* altura * edad: Ya que existe una relación importante entre la edad y la altura en el rango de edades del dataset (12 a 18 años). Esta relación se entiende que que a pecta al peso al igual que la altura. 
*  altura * genero: Parece haber una relación definida entre la altura y el genero, ya que al agregar esta variable
aumneta ligeramente el $R^2$ Ajustado.


```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_3 <- lm(
  peso~ 
    altura + 
    genero + 
    consumo_semanal_snacks +
    consumo_semanal_comida_grasa + 
    altura * edad + 
    altura * genero,
  data = train_set
)

coefficients_summary(model_3)
anova_summary(model_3)
glance(model_3)
varImp(model_3)
```

**Modelo 4**

En este modelo principalmente se busco sumar explicacbilidad al modelo, es decir e mayor $R^2$ posible si
prestar atencion si las variables son explicativas o sus categorias en caso de ser categoricas. Para esto
se agregaron todas las variables del tataset y luego quellas combinacion que sumaron $R^2$ en el *modelo 4*.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_4 <- lm(
  peso ~
  edad +
  genero +
  nivel_educativo + 
  altura + 
  frecuencia_hambre_mensual + 
  dias_consumo_comida_rapida +
  edad_consumo_alcohol + 
  consumo_diario_alcohol + 
  dias_actividad_fisica_semanal +
  consumo_semanal_frutas +
  consumo_semanal_verdura +
  consumo_semanal_gaseosas +
  consumo_semanal_snacks +
  consumo_semanal_comida_grasa +
  altura * edad + 
  altura * genero + 
  altura * nivel_educativo,
  data = train_set
)

coefficients_summary(model_4)
anova_summary(model_4)
glance(model_4)
varImp(model_4)
```

Finalmente, si comparamos los modelos por $R^2$ Ajustado, se puede apreciar que el modelo 5 llega a captar la 
mayor varianza explicada sobre el conjunto de entrenamiento. Por supuesto esto no dice nada acerca de la 
performance del modelo en test, pero si que tiene la mejor capacidad para extraer información de los dato 
de entrenamiento.

### 4.2. Evaluar la performance del modelo inicial, el modelo categóricas con las categorías redefinidas de la variable consumo_semanal_snacks y los modelos desarrollados en este punto en el dataset de entrenamiento y evaluación (usar dataset "encuesta_salud_test.csv"). La evaluación de performance consiste en comparar en ambos sets la performance en términos del R cuadrado ajustado, RMSE y MAE ¿Cuál es el mejor modelo para nuestro objetivo de predecir el peso? ¿Por qué?

Ahora comparamos la performance de todo los modelos al evaluar el error de los mismo al predecir el
peso en el conjunto de train y test tanto para RMSE como MAE:

**RMSE**

```{r}
eval_summary <- function(metric_fn = rmse) {
  summary_part_1 <- list(
    'Modelo 1' = model_1, 
    'Modelo 2' = model_2, 
    'Modelo 3' = model_3,
    'Modelo 4' = model_4
  ) %>% train_test_eval_metric_summary(test_set = test_set, metric_fn = metric_fn)
  
  summary_part_2 <- list('Modelo 2 - Re-definición 1' = model_2_redefinicion_1) %>% 
    train_test_eval_metric_summary(test_set = test_set_snack_1, metric_fn = metric_fn)
  
  summary_part_3 <- list('Modelo 2 - Re-definición 2' = model_2_redefinicion_2) %>% 
    train_test_eval_metric_summary(test_set = test_set_snack_2, metric_fn = metric_fn)
  
  summary <- summary_part_1 %>% 
    union_all(summary_part_2) %>% 
    union_all(summary_part_3) %>%
    arrange(test)
  
  min_test_error <- summary %>% 
    pull(test) %>% 
    min()
  
  summary %>% mutate(diff_min_test = abs(test - min_test_error))
}

eval_summary_result <- eval_summary(rmse)
eval_summary_result
```

Si utilizamos la métrica RMSE podemos ver que el modelo **Modelo 2 - Re-definición 1** tiene el menor error
al evaluarlo con el conjunto de test. Por otro lado, el que tiene menor diferencia de error entre test y entrenamiento. Esto nos dice que tiene el menor grado de sobre-ajuste (overfitting) al conjunto de entrenamiento. 

El **Modelo 4**  por otro lado es el que mas se ajusta al conjunto de entrenamiento ya que tiene el menor error en train
y ademas la mayor diferencia entre train y test. Sucede algo muy similar con el modelo **Modelo 3** pero en menor medida.

Otro punto a tener es la diferencia en el error en test para **Modelo 2 - Re-definición 1**  y **Modelo 4**. Parece ser una diferencia my baja en términos de error lo que sugiere que performan de formar similar para este conjunto de test, pero
no podemos asegurarlo con otro conjunto de tst distinto. Por todas estas cuestiones bajo la metrica RMSE el modelo
 **Modelo 2 - Re-definición 1** parece ser el mas razonable.

**MAE**

```{r warning=FALSE}
eval_summary(mae)
```

Usan la métrica MAE el **Modelo 4** es el que tiene el menor error en test seguido de **Modelo 2 - Re-definición 1**.
**Modelo 2 - Re-definición 1** parece ser el modelo que menos sobre-ajuste y sorprendente-mente el **Modelo 4** a pesar de ser
el que menos error tiene el test también es el que mas sobre ajusta al conjunto de test dado. Por esta ultima cuestión
la mejor opción el el modelo **Modelo 2 - Re-definición 1** ya que el modelo **Modelo 4** es el que peor generaliza.

Finalmente, según ambas métricas **Modelo 2 - Re-definición 1** es el modelo mas adecuado.

## 5. Diagnóstico del modelo

Analizar en profundidad el cumplimiento de los supuestos del modelo lineal para el modelo inicial.

```{r fig.height=4, fig.width=6, warning=FALSE, fig.align='center'}
plot(model_1)
```

**Homocedasticidad**

Al visualizar el primer gráfico (Residuos vs. Valores ajustados) se puede apreciar que hay presencia
de homocedasticidad, ya que a medida que aumentan los valores predichos la variabilidad o amplitud
de los residuos parece mantenerse en los mismo niveles. Dadas esta condiciones podemos decir que se
cumple el supuesto de varianza constante.

**Normalidad**

Al visualizar el diagrama **QQ-Plot** podemos observas que en el extremo derecho, el modelo
sobre-estima el peso del los individuos ya que hay una gran diferencia entre los valores predichos y
los valores esperados teóricos. Lo contrario sucede a izquierda, donde el modelo subestima el valor
de peso en comparación al valor esperado teórico, aunque los valores de los residuos son menores en
este caso. Finalmente el QQ-Plot muestra un grado de alejamiento pronunciado de una distribución
normal teórica y por lo tanto no se cumple el supuesto de normalidad del modelo.

**Apalancamiento (Leverage)**

Si observamos el gráfico de **Residuos vs Apalacamiento** vemos varias observaciones o individuos
que se alejan a derecha del cumulo principal. Estos ejercen un alejamiento de las prediciones del
modelo vs los valores reales a partir de un apalancamiento(leverage) 0.0025 y es mas pronunciado
desde 0.0035. Finalmente, vemos un grado importante de desvió de las predicciones vs valores reales
y por ente un grado importante de apalancamiento(leverage).

A continuación se pueden ver lo individuos que producen mayor apalancamiento(leverage) y por ende
sesgo en las predicciones del modelo:

```{r}
augment(model_1) %>%
  filter(.hat>0.0025) %>%
  arrange(.hat)
```

## 6. Modelo Robusto

### 6.1. Leer el archivo "encuesta_salud_modelo6.csv". Este último consiste en el dataset original de train
con la incorporación de algunas observaciones adicionales que pueden incluir valores atípicos. En
particular, observar la relación entre peso y altura ¿Qué ocurre con estos nuevos datos?

A continuación se carga el conjunto de entrenamiento en crudo, es decir sin pre-procesamiento. Luego
se resumen los valores de las variables categóricas y se tranforman lo misssings a NA's:

```{r warning=FALSE}
original_train_set <- load_original_train_set() %>% 
  preprocess() %>% 
  shorten_values() %>% 
  process_missings()

original_train_set %>% missings_summary()
```

Se aprecia que hay muy pocos missing values. Por otro lado estos no se eliminan ya que el modelo
lineal por defecto los filtra. Comparemos las distribuciones del peso vs. altura en ambos conjunto
de entrenamiento:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
box_plots(train_set %>% select(peso, altura), title = 'Peso va Altura train_set')
box_plots(original_train_set %>% select(peso, altura), title = 'Peso va Altura original_train_set')
```

En el dataset de entrenamiento original la variable peso tiene prácticamente el doble de outliers
que el dataset procesado.


### 6.2. Entrenar el modelo inicial con estos nuevos datos y comentar qué se observa en los coeficientes 
estimados y las métricas de evaluación (R cuadrado ajustado, RMSE y MAE) respecto al modelo entrenado 
con el set de entrenamiento original.

**Modelo 6**

Definimos un modelo igual al **modelo 1** pero entrenando en el dataset de entrenamiento original.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_6 <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = original_train_set
)

coefficients_summary(model_6)
anova_summary(model_6)
glance(model_6)
```

```{r}
compare_r2(model_1, model_6)
```

Hay una diferencia porcentual muy alta del $R^2$ ajustado en ambos modelos. El hecho de que existan outliers 
en el train set original produce que disminuya la explicabilidad del mismo en train.


```{r}
models <- list('Modelo 1' = model_1, 'Modelo 6' = model_6)
models %>% eval_models_summary(test_set,  metric_fn = rmse)
models %>% eval_models_summary(test_set,  metric_fn = mae)
```

En este caso los resultados son muy consistentes con ambas métricas (RMSE y MAE). En ambos caso el 
**Modelo 1** es el que logra un menor error en test, ademas de tener la menor diferencia entre train y test.
Por otro lado, con ambas métricas se aprecia que el **Modelo 6** tiene peor performance en train que en test.
Esto podría deberse a que el modelo tiene ejemplos mas difíciles de ajustar en train que en test, ya sea por 
efecto de los outliers o por que existe algún ejemplo extra el cual es difícil de ajustar para el modelo.
A pesar de esto, hay muy poca diferencia midiendo el RMSE train vs. test para ambos modelos.

### 6.3. Entrenar un modelo robusto con la misma especificación que el modelo inicial
sobre los nuevos datos. Comparar los coeficientes y su performance (RMSE y MAE) respecto al modelo
inicial no robusto entrenado en este punto. ¿Qué puede concluir al respecto?

**Modelo 7**

Definimos un modelo igual al **modelo 1** entrenando en el dataset de entrenamiento original y
usamos un modelo lineal robusto.

```{r}
model_robusto <- rlm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = original_train_set
)

coefficients_summary(model_robusto)

models <- list('Modelo 1' = model_1, 'Modelo Robusto' = model_robusto)
models %>% eval_models_summary(test_set,  metric_fn = rmse)
models %>% eval_models_summary(test_set,  metric_fn = mae)
```

Midiendo con RMSE los resultados son muy similares al punto anterior. En este caso el **Modelo Robusto** pierde 
con respecto al **Modelo 1**, inclusive por una diferencia mucho mas grande en test que el **Modelo 6**. El modelo 
robusto sufre del mismo problema que el **Modelo 6** donde tenemos un error en train mayor que test. Ahora
Midiendo con MAE los resultados se invierten y el **Modelo Robusto** gana por una diferencia poco significativa.

Como conclusión, no parece claro que el **Modelo Robusto** o el **Modelo 6** mejor que el **Modelo 1** en otro 
conjunto de test distinto. Por otro lado, pareciera que el dataset original con outliers esta dificultando el 
ajuste de los modelos en el entrenamiento. ^por otro lado no se aprecia una diferencia significativa en la performance
del **Modelo 6** y el **Modelo Robusto**.
