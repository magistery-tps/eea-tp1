---
title: |
    | Maestría en Explotación de datos y Descubrimiento de conocimiento
    |
    |
    | Materia: Enfoque Estadistico del Aprendizaje
    | Trabajo práctico 1: Regresion Lineal
author: "Adrian Norberto Marino"
date: "2021/09/19"
fig_width: 3 
fig_height: 3 
output:
  html_document: 
    highlight: pygments
    theme: sandstone
    includes:
      before_body: ./header.html
      after_body: ./footer.html
editor_options: 
  markdown: 
    wrap: 100
---

## 2. Modelo inicial

Se plantea la siguiente primera alternativa para modelar el peso:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * diasActividadFisicaSemanal + \beta5 * consumoDiarioAlcohol$

Primero se cargan las librerias necesarias:

```{r, results='hide'}
options(warn=-1)
rm(list=ls())
gc()
options(warn=-2)
clean <- function() { cat("\014") }
clean()
```

```{r, results='hide'}
# install.packages("pacman") -- Descomentar par instalar pacman
library(pacman)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
import('../src/preprocessing.R')
import('../src/model.R')
import('../src/plot.R')
clean()
```

A continuación se cargan los conjuntos de entrenamiento y test. también se resumen los valores de
las variables categóricas y se excluyen los registros con missings, ya que son muy pocos en
comparación de la cantidad total de resgístros.

```{r}
train_set <- drop_missings(shorten_values(preprocess(load_train_set())))
test_set  <- drop_missings(shorten_values(preprocess(load_test_set())))
clean()
glimpse(train_set)
```

Se fija la semilla y se validan las proporciones de los conjuntos de entrenamiento y test:

```{r}
set.seed(25)

show_train_test_props(train_set, test_set)
```

**Modelo 1**

Se plantea el primer modelo lineal:

```{r}
model_1 <- lm(
  peso ~ altura + edad + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set
)
```

**¿Cuál es la interpretación de cada uno de los coeficientes estimados?**

Veamos a continuación un resiment de los coeficiente del primer modelo:

```{r}
coefficients_summary(model_1)
```

Al analizar cada coeficiente se encuentra que:

-   $\hat{\beta_0}$ (Ordenada al origen) de valor -72.72 Kg, es el peso esperado o promedio de un
    individuo que tiene cero altura, edad, actividad física y consumo diario de alcohol (Medido en
    tragos). Esto no es interpretable, ya que miniamente una persona tiene que tener una altura
    superior a cero y no puede tener un peso negativo, pero si podría no realizar actividad física
    ni consumir alcohol.

-   El coeficiente $\hat{\beta_1}$ de valor 680 gramos, corresponde a la altura del individuo. Este
    coeficiente indica que dada una edad, consumo de alcohol diario (Medido en tragos) y días de
    actividad física semanal fijos, cada incremento en 1 cm adicional en la altura del individuo
    implica un aumento de su peso esperado o promedio de 680 gramos.

-   El coeficiente $\hat{\beta_2}$ de valor 1.33 Kg, corresponde a la edad del individuo. Este
    coeficiente indica que dada una altura, días de actividad física y consumo de alcohol diario
    fijos, cada vez que el individuo cumple año su peso esperado o promedio aumenta en 1.33 kg.

-   El coeficiente $\hat{\beta_3}$ de valor 77.59 gramos, corresponde a los días de actividad física
    semanal que realiza el individuo. Este coeficiente indica que dada una altura, edad y consumo de
    alcohol diario (Medido en tragos) fijos, cada vez que un individuo realiza un día mas de
    actividad física semanal su peso esperado o promedio disminuye en 77.59 gramos.

-   El coeficiente $\hat{\beta_4}$ de valor -8 gramos, corresponde al nivel de consumo diario de
    alcohol del individuo. Este coeficiente indica que dada una altura, una edad y días de actividad
    física semanal fijos, cada vez que el individuo consume un trago de alcohol su peso esperado o
    promedio disminuye en 8 gramos. A simple vista podrá no llegar a tener sentido, ya que a mayor
    consumo de alcohol el peso debería aumentar, ya sea por el peso del propio liquido como el peso
    equivalente en grasas.

**¿Son significativos los coeficientes?**

Para determina si los coeficientes son aptos para explicar el peso de un individuo se realiza un
${T}$ test para cada coeficiente en el cual se evalúan las siguientes hipótesis:

-   ${H_0: \beta_i = 0}$
-   ${H_1: \beta_i \neq 0}$

Si ${\beta_i \neq 0}$ podemos decir que existe una diferencia estadisticamente significativas del
coeficiente ${\beta_i}$ del valor cero, y por lo tanto el coeficiente ${\beta_i}$ explicar la
variable ${y}$ (Peso en nuestro caso).

Luego analizando la salida de **coefficients_summary** concluimos que:

-   Los coeficientes correspondientes de la altura(${\beta_1}$) y edad(${\beta_2}$) tienen un
    p-valor \< 0.05. Por lo tanto se rechaza la hipótesis nula y ambos resultan estadistitamente
    significativas para explicar el peso. Por otro lado, se puede apreciar que los intervalos de
    confianza (del 95%) de ambos coeficientes no incluyen al cero.
-   Lo contrario sucede con días de actividad física semanal(${\beta_3}$) y consumo de alcohol
    diario (${\beta_4}$), dato que ambos no rechazar la hipótesis nula (p-valor > 0.05) y por lo
    tanto no existe una diferencia significativa del cero. Finalemnte, no hay evidencia
    estadistitamente significativas para explicar el peso.

**¿El modelo resulta significativo para explicar el peso?**

```{r}
glance(model_1)
```

Para determinar si es modelo es significativo para explicar el peso de un individuo se realiza un
$F$ test con las siguientes hipótesis:

-   $H_0: β_1 = β_2 = · · · = β_{p−1} = 0$
-   $H_1:$ Por lo menos un $β_k$ ($k = 1, 2,..., p−1$) es distinto de 0.

$H_0$ afirma que no hay vinculo entre la variable ${y}$(Peso) y las variables regresoras. $H_1$
afirma que al menos una de las variables regresoras sirve para predecir la variable ${y}$ (Peso).

Veamos los resultados de $F$ test:

```{r}
glance(model_1)
```

Dado que el p-valor \< 0.05 e igual a 0, con mucha certeza podemos decir que al menos una de las
variables regresoras permite explicar el peso. Esto concuerda con los resultados de los $T$ test
para las los coeficientes correspondientes a Altura y Edad.

**¿Qué porcentaje de la variabilidad explica el modelo?**

Según el valor de $R^2$ ajustado (**adj.r.squared**), este modelo llega a explica el 35% de la
variabilidad del dataset de entrenamiento, lo cual no es un valor bajo pero tampoco es despreciable.

## 3. Modelo categóricas

Se sugiere probar un modelo que incorpore el consumo semanal de snacks y una interacción entre el
género y la edad, en lugar de actividad física y consumo de alcohol. Además se pide explicitamente
que la categoría "No comí comida salada o snacks en los últimos 7 días" de la variable
**consumo_semanal_snacks** se encuentre como nivel/categoría basal.

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

Primero definimos cual es la primera categoría en cada factor, ya que esta sera la que el modelo
defina como categoría basal:

```{r}
train_set$consumo_semanal_snacks <- factor(
  train_set$consumo_semanal_snacks,
  levels=c("0","<=3", "4-6",  "7", "14", "21", ">=28"), 
  ordered=FALSE
)
table(train_set$consumo_semanal_snacks)
```

Se puede apreciar que la primera categoría corrspondeo a 0 consumo de snacks semanal.

```{r}
table(train_set$genero)
```

Por otro lado la categoría genero esta correstamente balanceada.

**Modelo 2**

Definimos el nuevo modelo:

```{r}
model_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set
)
```

**¿Cuál es la interpretación de los coeficientes estimados para las categorías de
consumo_semanal_snacks y genero \* edad? ¿Son significativas?**

```{r}
coefficients_summary(model_2)
```

Si interpretamos los coeficientes que son significativos:

-   La altura y la edad siguen siendo significativos al igual que el modelo anterior, con la
    diferencia que cambiaron ligeramente sus valores a 0.64 y 1.21.

-   Para una **altura**, **edad** fijos, la diferencia de peso de los individuos que consumen snacks
    hasta 3 veces por semana de los que no consumen(Categoría basal) es de -1.436 kg. Esto a simple
    vista pareciera no tener sentido, ya que quienes consumen snacks hasta 3 veces por semana
    deberían tener un peso menor. Lo mismo sucede con las categorías **consumo_semanal_snacks** 4-6
    y >=28.

**¿Qué porcentaje de la variabilidad explica el modelo? En caso de detectar que existen categorías
no significativas de la variable consumo_semanal_snacks evaluar si la variable es significativa en
su conjunto y, en caso afirmativo, proponer una redefinición de las mismas que permita obtener una
mayor proporción de categorías significativas individualmente. Luego, analizar si existen cambios en
la variabilidad explicada por el modelo.**

Viendo el resultado de **coefficients_summary** se aprecia que las siguientes categorías de
**consumo_semanal_snacks** no son significativas:

-   2 veces al día (14 veces/semana)
-   4 a 6 veces durante los últimos 7 (4 a 6 veces semana)
-   3 veces al día (21 veces/semana)

Pero si son significativas los extremos:

-   De 1 a 3 veces/semana

-   De 28 o mas veces/semana

A continuación se realiza un $F$ test para evaluar la significatividad conjunta de las categóricas
de la variable **consumo_semanal_snacks** para explicar el peso.

El $F$ test también llamando ANOVA (Análisis de la variarían) se realiza para probar la
significatividad conjunta de todos los valores de una variable categórica.

Las hipótesis son las siguientes:

-   $H_0: β_q = β_{q+1} = · · · = β_{p−1} = 0$

-   $H_1:$ por lo menos uno de los $β_k$ (con $k$ entre $q$ y $p−1$) es tal que $β_k \neq 0$.

Luego si todosl los coeficientes asociados a los valores de variable categórica son cero, se rechaza
la hipótesis nula y por lo tanto la variable no es significartiva para explicar el peso en nuestro
caso.

A continuación veremos el p-valor resultado de aplicar $F$ test para cada variable del modelo:

```{r}
anova_summary(model_2)
```

Podemos apreciar que el p-value \< 0.005 para la variable **consumo_semanal_snacks**. Por lo tanto
se rechaza la hipótesis nula y podemos decir en su conjunto resulta estadísticamente significativa
para explicar el peso. Luego, como la variable **consumo_semanal_snacks** es significativa vale la
pena re-definirla.

Por otro lado, la combinación de variables genero-edad no es estadísticamente significativa para
explicar el peso, pero si lo es el genero en forma separada. Finalmente, como ya vimos en pasis
anteriores, edad y altura son significativas.

Veamos a continuación las distribuciones de las categorías de la variable **consumo_semanal_snacks**
ordenadas por la mediana del peso:

```{r}
segmented_box_plot(
  train_set, 
  column        = 'peso', 
  segmented_by  = 'consumo_semanal_snacks',
  title         = 'Consumo de snacks ordenado por la mediana del peso',
  y_label       = 'Peso (Kg)',
  y_limits      = c(10, 130),
  x_label       = 'Consumo de snacks (Veces/Semana)'
)
```

A simple vista no parece haber una gran diferencia, pero si se aprecia que los extremos difieren del
los valores centrales.

A continua con se promane una nueva definición de la variable **consumo_semanal_snacks**. Primero se
realiza el promediodel peso para cada categoría de la variable **consumo_semanal_snacks**:

```{r}
peso_medio_by_nivel_consumo_snack = train_set %>% 
  group_by(consumo_semanal_snacks) %>%
  summarise(promedio = mean(peso))

ggplot(data = peso_medio_by_nivel_consumo_snack, aes(x = promedio)) + 
  geom_boxplot(alpha = 0.75, fill="blue") +
  labs(title = "Peso promedio por cada categoria de consumo de snacks") +
  labs(x = "Peso medio") +
  theme_bw()
```

```{r}
peso_medio_by_nivel_consumo_snack  <- peso_medio_by_nivel_consumo_snack$promedio

peso_medio_by_nivel_consumo_snack
quantile(peso_medio_by_nivel_consumo_snack)
```

Se puede apreciar que es una distribución asimétrica sesgada a derecha, ya que los mayores valores
se encueran arriba del segundo cuantil (Mediana).

A continuación se re-definen las categorías originales por 3 nueva categorías: Bajo, Medio, Alto.
Esta categorías estan asociadas al peso de de individuo. Si el indivídio tiene un peso menor al Q1,
se le asigna el nivel Bajo, si esta entre Q1 y Q3 sera Medio y Alta arroba de Q3. Finalmente a
continuación se transforma la variable en el conjunto de entrenamiento y en test se usas los los
cuantíles generados con en conjunto de entrenamiento:

```{r}
q1 <- quantile(peso_medio_by_nivel_consumo_snack)[2]
q3 <- quantile(peso_medio_by_nivel_consumo_snack)[4]

train_set2 <- train_set %>%
  mutate(consumo_semanal_snacks = case_when(peso <  q1 ~ "Bajo", peso >= q3 ~ "Alto", TRUE ~ "Medio"))

test_set2 <- test_set %>%
  mutate(consumo_semanal_snacks = case_when(peso <  q1 ~ "Bajo", peso >= q3 ~ "Alto", TRUE ~ "Medio")) %>% 
  mutate(consumo_semanal_snacks = as.factor(consumo_semanal_snacks))

test_set2 %>% segmented_box_plot(
  column        = 'peso', 
  segmented_by  = 'consumo_semanal_snacks',
  title         = 'Consumo de snacks ordenado por la mediana del peso en Test',
  y_label       = 'Peso (Kg)',
  y_limits      = c(40, 100),
  x_label       = 'Consumo de snacks (Veces/Semana)'
)
```

Se puede apreciar que en el conjunto de test no hay valores medio, pero existe en el conjunto de
entrenamiento.

**Modelo 3**

A continuación definimos un nuevo modelo igual al anterior pero ahora ya usando la re-definición de
la variable **consumo_semanal_snacks:**

```{r}
model_3 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set2
)
```

```{r}
models <- list('Modelo 1'=model_1, 'Modelo 2'=model_2, 'Modelo 3'=model_3)

coefficients_summary(model_3)
anova_summary(model_3)

models %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

Finalmente se aprecia que la nueva categorización de la variable aumenta el $R^2$ Ajustado a casi el
doble (Del 35.7 al 64.7%). Si bien esto mejora la capacidad explicativa del modelo, en pasos
posteriores se deberá determina si produce o no overfitting sobre el conjunto de entrenamiento.

## 4. Modelos propios y evaluación

Realizar 2 modelos lineales múltiples adicionales y explicar breve-mente la lógica detrás de los
mismos (se valorará la creación y/o inclusión de variables nuevas).

Evaluar la performance del modelo inicial, el modelo categóricas con las categorías redefinidas de
la variable **consumo_semanal_snacks** y los modelos desarrollados en este punto en el dataset de
entrenamiento y evaluación (usar dataset "encuesta_salud_test.csv").

La evaluación de performance consiste en comparar en ambos sets la performance en términos del R
cuadrado ajustado, RMSE y MAE.

Al continuación se define 2 modelos.

**Modelo 4**

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * diasActividadFisicaSemanal + \beta_6 * altura * genero$

Se utilizo la redefinición de la variable **consumo_semanal_snacks** como base. Ademase se agregar
la variable dias_actividad_fisica_semanal entendiendo que tiene una influencia iportante en el peso
y luego la asociacion altura \* genero ya que en general mas mujeres tienen a ser mas bajar que los
varones y vise versa.

```{r}
model_4 <- lm(
  peso~ 
    altura + 
    edad + 
    genero + 
    consumo_semanal_snacks +
    dias_actividad_fisica_semanal +
    altura*genero,
  data = train_set2
)

coefficients_summary(model_4)
anova_summary(model_4)
glance(model_4)
```

```{r}
train_set3 <- column_mean_quantile_binning(train_set2, 'dias_actividad_fisica_semanal')
test_set3  <- column_mean_quantile_binning(test_set2,  'dias_actividad_fisica_semanal')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_frutas')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_frutas')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_verdura')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_verdura')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_comida_grasa')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_comida_grasa')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_gaseosas')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_gaseosas')

segmented_box_plot(
  test_set3, 
  column        = 'peso', 
  segmented_by  = 'dias_actividad_fisica_semanal',
  title         = 'Niveles actividad fisica ordenados por la mediana del peso en Test',
  y_label       = 'Peso (Kg)',
  y_limits      = c(40, 100),
  x_label       = 'Niveles de actividad física (Dias)'
)
```

**Modelo 5**

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * diasActividadFisicaSemanal + \beta_6 * consumoSemanalFrutas + \beta_7 * consumoSemanalVerduras + \beta_8 * consumoSemanalGrasas + \beta_9 * consumoSemanalGaseosas$

Se utilizo la redefinición de la variable **consumo_semanal_snacks** como base. Ademase se agregar
la variable consumo_semenal_frutras/verduras/grasas/gaseaosas entendiendo que también tiene una
influencia importante en el peso.

```{r}
model_5 <- lm(
  peso ~ 
  edad +
  genero +
  altura +
  consumo_semanal_snacks +
  consumo_semanal_frutas + 
  consumo_semanal_verdura,
  data = train_set3
)

coefficients_summary(model_5)
anova_summary(model_5)
glance(model_5)
```

```{r}
c(models, list('Modelo 4'=model_4, 'Modelo 5'=model_5)) %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

Finalmente, si comparamos los modelos por $R^2$ Ajustado, se puede apreciar que el modelo 5 (con
todas las variables categóricas re-definidas) llega a captar la mayor varianza explicada sobre el
dataset de entrenamiento. Por supuesto esto no dice nada acerca de la performance del modelo en
test, pero si que tiene la mejor capacidad para extraer información de los dato de entrenamiento.

**¿Cuál es el mejor modelo para nuestro objetivo de predecir el peso? ¿Por qué?**

Ahora comparamos la performance de todo los modelos al evaluar el error delos mismo al predecir el
peso en el conjunto de train y test tanto para RMSE como MAE:

**RMSE**

```{r}
custom_models_evaluation_summary(
  model_1, model_2, model_3, model_4, model_5,
  test_set, test_set2, test_set3,
  metric_fn = rmse
)
```

Si utilizamos la métrica RMSE podemos ver que el modelo 5 tiene el menor error en el conjunto de
test. Por otro ladoes el que tiene la mayor diferencia de error entre test y entrenamiento. Esto nos
dice que podría estar sobre-ajustandose al conjunto de entrenamiento. El modelo 3 tiene un error en
test muy cercano y ademas tiene un diferencia entre test y train mucho menor. por esto ultimo parece
ser el mejor modelo ya que tiene prácticamente el menor error posible y también el menor
sobre-ajuste al conjunto de entrenamiento.

**MAE**

```{r}
custom_models_evaluation_summary(
  model_1, model_2, model_3, model_4, model_5,
  test_set, test_set2, test_set3,
  metric_fn = mae
)
```

Si medimos a partir del MAE sucede algo muy similar, El modelo 3 es es que tiene menor error y
ademas menos sobre-ajuste.

Finalmente, según ambas metricas el moejor modelo es el **Modelo 3**.

## 5. Diagnóstico del modelo

Analizar en profundidad el cumplimiento de los supuestos del modelo lineal para el modelo inicial.

```{r}
plot(model_1)
```

**Homosedastisidad**

Al visualizar el primer gráfico (Residuos vs. Valores ajustados) se puede apreciar que no hay
presencia de homocedastrisisdad, ya que los valores predicho, la variabilidad o amplitud de los
residuos parece mantenese con cierta regularidad. Dadas esta condiciones podemos decir que se cumple
el supuesto de variánza constante.

Normalidad

Al visualizar el diagrama **QQ-Plot** podemos observas que en el extremo derecha, el modelo sobre
estima el peso del los individuos ya que hay una gran diferencia positiva entre el valor predicho y
el valor esperado teórico. lo mis sucede a izquierca pero en menor medida, donde el modelo subestima
el valor de peso en comparacion al valor esperado teórico. Como dato adiciona este grafito
corresponde a una districión sesgada a derecha, también conocido como sesgo positivo. Finalmente el
QQ-Plot no muestra un grado de alejamiento pronunciado de una dsitricion normal teórica y decimos
que no se cumple el supuesto de normalidad del modelo.

Apalancamiento (Leverage)

```{}
```

Si observamos el gráfico de **Residuos vs Apalacamiento** vemos que varias observaciones o
individuos que se alejan del cumulo de principal. Estos ejercen un apuntalamiento sobre el valores
predicho del modelo a partir de un apalancamiento(leverage) 0.0020 y es mas pronunciado desde 0.0025. Finalmente
vemos un grado importante de desvió de las predicciones vs su vor esperado.

A continuación se pueden ver lo individuos que producen mayor apalancamiento(leverage) y por ende sesgo en al
predicción del modelo:

```{r}
augment(model_1) %>%
  filter(.hat>0.00245) %>%
  arrange(.hat)
```

## 6. Modelo Robusto

Leer el archivo "encuesta_salud_modelo6.csv". Este último consiste en el dataset original de train
con la incorporación de algunas observaciones adicionales que pueden incluir valores atípicos. En
particular, observar la relación entre peso y altura ¿Qué ocurre con estos nuevos datos? Entrenar el
modelo inicial con estos nuevos datos y comentar qué se observa en los coeficientes estimados y las
métricas de evaluación (R cuadrado ajustado, RMSE y MAE) respecto al modelo entrenado con el set de
entrenamiento original. Entrenar un modelo robusto con la misma especificación que el modelo inicial
sobre los nuevos datos. Comparar los coeficientes y su performance (RMSE y MAE) respecto al modelo
inicial no robusto entrenado en este punto. ¿Qué puede concluir al respecto?

```{r}
original_train_set <- shorten_values(preprocess(load_original_train_set()))
missings_summary(original_train_set)
new_train_set <- drop_missings(original_train_set)
missings_summary(new_train_set)
```

```{r}
nrow(original_train_set)
nrow(new_train_set)
```

```{r}
box_plots(
  train_set %>% select(peso, altura), 
  title = 'Comparativas de distribuciones del peso y la altura'
)

box_plots(
  new_train_set %>% select(peso, altura), 
  title = 'Comparativas de distribuciones del peso y la altura'
)
```

En el dataset de test original la variable peso tiene practicamente el doble de outliers que el
dataset procesasdo.

```{r}
model_1_1 <- lm(
  peso ~ altura + edad + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = new_train_set
)

coefficients_summary(model_1_1)
anova_summary(model_1_1)
glance(model_1_1)
```

```{r}
print(paste('Disminicion de adj.r.squared:', abs(0.352113 - 0.2734821) * 100, '%'))
```

Dada la presencia de outliers en la variable peso, el R\^2 ajustado baja con respecto al modelo
inicial.

```{r}
models <- list('Modelo 1_1'=model_1_1)

models_evaluation_summary(models, train_set, metric_fn = rmse)
models_evaluation_summary(models, train_set, metric_fn = mae)
```

Por otro lado, aumento el error de predicción tanto en train como en test. Finalmente, el modelo
tiene un grado de overfitting mucho mayor que los modelos anteriores, ya que la métrica de
evaluación en test y train tiene una diferencia muy pronunciada de 1.7 puntos.

Pregunta: A que se refiere con entrenar un modelo robusto con las misma especificaciones del modelo
inicial????

```{r}
p_load(MASS)

model_1_2 <- rlm(
  peso ~ altura + edad + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = new_train_set
)
coefficients_summary(model_1_2)
anova_summary(model_1_2)
```

```{r}
models <- list('Modelo 1_1'=model_1_1, 'Modelo 1_2'=model_1_2)

models_evaluation_summary(models, test_set, metric_fn = rmse)
models_evaluation_summary(models, test_set, metric_fn = mae)
```
