---
title: |
    | Maestría en Explotación de datos y Descubrimiento de conocimiento
    |
    |
    | Materia: Enfoque Estadistico del Aprendizaje
    | Trabajo práctico 1: Regresion Lineal
author: "Adrian Norberto Marino"
date: "2021/09/19"
fig_width: 3 
fig_height: 3 
output:
  html_document:
    highlight: pygments
    theme: sandstone
    toc: yes
    df_print: paged
    includes:
      before_body: ./header.html
      after_body: ./footer.html
  html_notebook:
    toc: yes
    toc_float: yes
    df_print: paged
editor_options: 
  markdown: 
    wrap: 100
---

## 2. Modelo inicial

### 2.1. Se plantea la siguiente primera alternativa para modelar el peso:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * diasActividadFisicaSemanal + \beta5 * consumoDiarioAlcohol$

Primero se cargan las librerías necesarias:

```{r message=FALSE, warning=FALSE}
options(warn=-1)
rm(list=ls())
gc()
options(warn=-2)
```

```{r message=FALSE, warning=FALSE}
# install.packages("pacman") -- Descomentar par instalar pacman
library(pacman)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
import('../src/preprocessing.R')
import('../src/model.R')
import('../src/plot.R')
```

A continuación se carga los conjuntos de entrenamiento y test. también se resumen los valores de las
variables categóricas y se excluyen las observaciones con valores faltantes, ya que son muy pocas
con respecto al total.

```{r message=FALSE, warning=FALSE}
train_set <- load_train_set() %>% 
  preprocess() %>% 
  shorten_values() %>%
  process_missings()

test_set <- load_test_set() %>% 
  preprocess() %>% 
  shorten_values() %>% 
  process_missings()
```

```{r}
glimpse(train_set)
```

Se fija la semilla y se validan las proporciones de los conjuntos de entrenamiento y test:

```{r}
set.seed(25)
show_train_test_props(train_set, test_set)
```

**Modelo 1**

Se plantea el primer modelo lineal:

```{r}
model_1 <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set
)
```

### 2.2. ¿Cuál es la interpretación de cada uno de los coeficientes estimados?

Veamos a continuación un resumen de los coeficiente del **modelo 1**:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_1)
```

Al analizar cada coeficiente se encuentra que:

-   $\hat{\beta_0}$ (Ordenada al origen) de valor -68.92 Kg, es el peso esperado o promedio de un
    individuo de genero femenino que tiene cero altura, edad, actividad física y consumo diario de
    alcohol. Esto no es interpretable, ya que una persona tiene que tener una altura superior a cero
    y no puede tener un peso negativo, pero si podría no realizar actividad física ni consumir
    alcohol.

-   El coeficiente $\hat{\beta_1}$ de valor 653 gramos, corresponde a la altura del individuo. Este
    coeficiente indica que dada una edad, genero, consumo de alcohol diario y días de actividad
    física semanal fijos, cada incremento en 1 cm adicional en la altura del individuo implica un
    aumento de su peso esperado o promedio de 653 gramos.

-   El coeficiente $\hat{\beta_2}$ de valor 1.378 kg, corresponde a la edad del individuo. Este
    coeficiente indica que dada una altura, genero, días de actividad física y consumo de alcohol
    diario fijos, cada vez que el individuo cumple un año su peso esperado o promedio aumenta en
    1.378 kg.

-   El coeficiente $\hat{\beta_3}$ de valor 1.224 kg, corresponde a los individuos de genero
    masculinos. Este coeficiente indica que dada una altura, edad, consumo de alcohol diario y días
    de actividad física semanal fijos, el peso promedio o esperado para el genero masculino es 1.224
    kg mayor al peso femenino (categoría basal). Por otro lado, el coeficientes no indica cunado mas
    alto es el peso del genero masculino respecto del femenino al fijar los demás coeficientes.

-   El coeficiente $\hat{\beta_4}$ de valor 99.1 gramos, corresponde a los días de actividad física
    semanal que realiza el individuo. Este coeficiente indica que dada una altura, edad, genero y
    consumo de alcohol diario, cada vez que un individuo realiza un día mas de actividad física
    semanal su peso esperado o promedio disminuye en 99.1 gramos.

-   El coeficiente $\hat{\beta_5}$ de valor -8 gramos, corresponde al nivel de consumo diario de
    alcohol del individuo. Este coeficiente indica que dada una altura, edad, genero y días de
    actividad física semanal fijos, cada vez que el individuo consume un trago de alcohol su peso
    esperado o promedio disminuye en 8 gramos. A simple vista podrá no llegar a tener sentido, ya
    que a mayor consumo de alcohol el peso debería aumentar, ya sea por el peso del propio liquido
    como el peso equivalente en grasas. Entiendo que puede tener un relación con los rangos de
    edades de los individuos que mas consumen alcohol (12 q 17 años), ya que estos se encuentran en
    pleno crecimiento.

### 2.3. ¿Son significativos los coeficientes?

Para determina si los coeficientes son aptos para explicar el peso de un individuo se realiza un
${T}$ test para cada coeficiente en el cual se evalúan las siguientes hipótesis:

-   ${H_0: \beta_i = 0}$
-   ${H_1: \beta_i \neq 0}$

Si ${\beta_i \neq 0}$ podemos decir que existe una diferencia estadisticamente significativas del
cero para coeficiente ${\beta_i}$, y por lo tanto el coeficiente ${\beta_i}$ explicar la variable
${y}$ (Peso en nuestro caso).

Luego analizando la salida de **coefficients_summary** concluimos que:

-   Los coeficientes correspondientes al acategoria basal ${\beta_1}$(Genero femenino),
    altura(${\beta_1}$), edad(${\beta_2}$) y genero masculino (${\beta_3}$) tienen $p-valor < 0.05$.
    Por lo tanto, se rechaza la hipótesis nula y resultan estadistitamente significativos para
    explicar el peso. Por otro lado, se puede apreciar que los intervalos de confianza del 95% no
    incluyen al cero.
-   Lo contrario sucede con días de actividad física semanal(${\beta_4}$) y consumo de alcohol
    diario (${\beta_5}$), dado que ambos no rechazar la hipótesis nula ($p-valor > 0.05$) y por lo
    tanto no existe una diferencia significativa del cero. Finalmente, no hay evidencia
    estadistitamente significativas de que estos coeficientes expliquen al peso.

### 2.4. ¿El modelo resulta significativo para explicar el peso?

Para determinar si es modelo es significativo para explicar el peso de un individuo se realiza un
$F$ test con las siguientes hipótesis:

-   $H_0: β_1 = β_2 = · · · = β_{p−1} = 0$
-   $H_1:$ Por lo menos un $β_k$ ($k = 1, 2,..., p−1$) es distinto de 0.

Donde: \* $H_0$ afirma que no hay vinculo entre la variable ${y}$(Peso) y las variables regresoras.
\* $H_1$ afirma que al menos una de las variables regresoras sirve para predecir la variable ${y}$
(Peso).

Veamos los resultados el $F$ test:

```{r}
glance(model_1)
```

Podemos apreciar que el $p-valor < 0.05$ e igual a 0. Con mucha certeza podemos decir que al menos
una de las variables regresoras permite explicar el peso. Esto concuerda con los resultados de los
$T$ test para las los coeficientes correspondientes a altura, edad y genero femenino(basa) y
masculino).

### 2.5. ¿Qué porcentaje de la variabilidad explica el modelo?

Según el valor de $R^2$ ajustado (**adj.r.squared**), este modelo llega a explica el 35% de la
variabilidad del dataset de entrenamiento, lo cual no es un valor bajo pero tampoco es despreciable.

### 2.6. ¿Que sucede si poner al genero masculino como variable basal?

```{r}
train_set_genero <- data.frame(train_set) 
train_set_genero$genero <- factor(
  train_set_genero$genero,
  levels=c('Masculino', 'Femenino'), 
  ordered=FALSE
)
table(train_set_genero$genero)
```

```{r}
model_genero <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set_genero
)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_genero)
```

```{r}
glance(model_genero)
```

**Observaciones**

-   En este caso, cambia el coeficiente $\beta_0$ para la categoría basal, manteniéndose los demás
    coeficientes.
-   Siguen siendo significativos los mismo coeficientes. La unica diferencia es que $\beta_0$(basal)
    representa al genero masculino y $\beta_3$ al femenino.
-   Se mantiene la significatividad global del modelo y el mismo $R^2$.
-   Como ultimo, cabe aclarar que al cambiar la categoría basar cambian las interpretaciones del
    modelo.

## 3. Modelo categóricas

### 3.1. Se sugiere probar un modelo que incorpore el consumo semanal de snacks y una interacción entre el

género y la edad, en lugar de actividad física y consumo de alcohol. Además se pide explicitamente
que la categoría "No comí comida salada o snacks en los últimos 7 días" de la variable
**consumo_semanal_snacks** se encuentre como nivel/categoría basal.

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

Primero validamos que las primeras categorías en cada variable de tipo factor sean las correctas, ya
que esta sera la que el modelo defina como categoría basal:

```{r}
table(train_set$consumo_semanal_snacks)
table(train_set$genero)
```

Se puede apreciar que la primeras categorías corresponden a 0 consumo de snacks semanal y genero
femenino. Por otro lado la categoría genero se encuentra balanceada.

**Modelo 2**

Definimos el nuevo modelo:

```{r}
model_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set
)
```

### 3.2. ¿Cuál es la interpretación de los coeficientes estimados para las categorías de

consumo_semanal_snacks y genero \* edad? ¿Son significativas?

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_2)
```

Si interpretamos los coeficientes que son significativos para el $T$ test:

1.  Coeficiente correspondiente al **consumo_semanal_snacks\<=3**:

Si fijamos los coeficientes correspondientes a la altura, edad, generoMasculino y
generoMasculino\*edad; el peso promedio o esperado de un individuo de consume snacks hasta 3 veces
por semana es 1.43 kg menor que aquellos que no consumen snacks.

2.  Sucede algo similar con las categorias **consumo_semanal_snacks4-6** y
    **consumo_semanal_snacks>=28** donde:

-   El peso para un individio que consume de 4 a 6 veces por semana es 2.25 kg menor que aquellos
    con no consumen snacks.
-   El peso para un individio que consume 28 veces a mas por semana es 2.6 kg menor que aquellos con
    no consumen snacks.

3.  Coeficiente correspondiente al **edad \* genero**:

Dado el modelo original:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \ \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

y sabiendo que el genero femenino toma el valor 0 y masculino 1. Si reemplazamos estos valores en el
modelo original encontramos que:

$E_f(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_4 * consumoSemanalSnacks$

El genero femenino tiene la ordenada $\beta0$ y las pendientes determinada por $\beta_1$, $\beta_2$
y $\beta_4$.

$E_m(peso) = (\beta_0 + \beta_3) + \beta_1 \* altura + (\beta_2 + \beta_2,3) * edad + \ \beta_4 * consumoSemanalSnacks$

El genero masculino tiene una ordenada que es la suma de la ordenada del genero femenino $\beta_0$
mas $\beta_3$. Luego cambia la pendiente $\beta_2$ de la edad, a la cual se le suma $\beta_2,3$

Luego, sabiendo que solo cambian los coeficientes correspondientes al genero y edad, si mantenemos
contantes los demás coeficientes obtenemos:

-   $E_f(peso) = \beta_0 + \beta_2 * edad + cte$
-   $E_m(peso) = (\beta_0 + \beta_3) + (\beta_2 + \beta_2,3) * edad$

Ahora reemplazamos por los coeficientes por lo valores que encontró el modelo:

-   Femenino:

    -   $E_f(peso) = -65.56456109 + 1.22539002 edad + cte$

-   Masculino:

    1.  $E_m(peso) = (-65.56456109 + -4.60464631) + (1.22539002 + 0.38927567) * edad + cte$
    2.  $E_m(peso) =-70.1692074 + 1.61466569 * edad + cte$

Finalmente, graficamos ambas rectas definiendo la $cte$ con un valor que de pesos positivos para
tener una gráfica consistente:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
cte = 100

train_set %>% 
  mutate(
    peso = ifelse(
      genero=='Femenino', 
      (-65.56456109 + 1.22539002 * edad) + cte,
      (-70.1692074 + 1.61466569 * edad) + cte
    ) 
  ) %>%
  ggplot(aes(x = edad, y = peso, colour=genero)) +
  geom_line() +
  ylab('Peso') +
  xlab('Edad')
```

Finalmente, se puede apreciar que las ordenadas de ambos géneros son distintas, donde el genero
femenino inicia desde un peso menor al masculino. Luego si variamos únicamente la edad, se aprecia
que el peso del genero masculino es mayor al femenino para la misma edad en todo los casos. Esto se
debe a que la resta correspondiente al genero masculina esta por arriba de la resta correspondiente
al genero femenino.

### 3.3. ¿Qué porcentaje de la variabilidad explica el modelo? En caso de detectar que existen categorías

no significativas de la variable consumo_semanal_snacks evaluar si la variable es significativa en
su conjunto y, en caso afirmativo, proponer una redefinición de las mismas que permita obtener una
mayor proporción de categorías significativas individualmente. Luego, analizar si existen cambios en
la variabilidad explicada por el modelo.

Viendo el resultado de **coefficients_summary** se aprecia que las siguientes categorías de
**consumo_semanal_snacks** no son significativas:

-   2 veces al día (14 veces/semana)
-   4 a 6 veces durante los últimos 7 (4 a 6 veces semana)
-   3 veces al día (21 veces/semana)

Pero si son significativas los extremos:

-   De 1 a 3 veces/semana
-   De 28 o mas veces/semana

A continuación se realiza un $F$ test para evaluar la significatividad conjunta de las categóricas
de la variable **consumo_semanal_snacks** para explicar el peso.

El $F$ test también llamando ANOVA (Análisis de la varianza) se realiza para probar la
significatividad conjunta de todos los valores de una variable categórica.

Las hipótesis son las siguientes:

-   $H_0: β_q = β_{q+1} = · · · = β_{p−1} = 0$
-   $H_1:$ por lo menos uno de los $β_k$ (con $k$ entre $q$ y $p−1$) es tal que $β_k \neq 0$.

Luego si todos los coeficientes asociados a los valores de variable categórica son cero, se rechaza
la hipótesis nula y por lo tanto la variable no es significartiva para explicar el peso en nuestro
caso.

A continuación veremos el p-valor resultado de aplicar $F$ test para cada variable del modelo:

```{r}
anova_summary(model_2)
```

Podemos apreciar que el $p-value < 0.005$ para la variable **consumo_semanal_snacks**. Por lo tanto
se rechaza la hipótesis nula y podemos decir en su conjunto resulta estadísticamente significativa
para explicar el peso. Luego, como la variable **consumo_semanal_snacks** es significativa vale la
pena re-definirla. Por otro lado, la combinación de variables genero-edad no es estadísticamente
significativa para explicar el peso, pero si lo es el genero en forma separada. Finalmente, como ya
vimos en pasos anteriores, edad y altura son significativas.

**Modelo 2: Redefinición 1**

Dado que no todas las categorías de la variable **consumo_semanal_snacks** sin significativas a
continuación se propone una re-definición de sus categorías que hace que todas ellas sean
significativas para el **modelo 2**.

```{r}
train_set_snack_1 <- train_set %>% mutate(consumo_semanal_snacks = case_when(
  consumo_semanal_snacks %in% c('<=3', '4-6' , '7')  ~ '<=7',
  consumo_semanal_snacks %in% c('14', '21', '>=28')  ~ '>=14',
  TRUE ~ as.character(consumo_semanal_snacks)
))
train_set_snack_1$consumo_semanal_snacks <- factor(
  train_set_snack_1$consumo_semanal_snacks,
  levels=c('0', '<=7', '>=14'), 
  ordered=FALSE
)
table(train_set_snack_1$consumo_semanal_snacks) 
```

```{r}
model_2_redefinicion_1 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_1
)

coefficients_summary(model_2_redefinicion_1)
anova_summary(model_2_redefinicion_1)
glance(model_2_redefinicion_1)
```

**Modelo 2: Redefinición 2**

En este caso se propone calcular la media del ratio **altura/edad** para cada categoría de la
variables **consumo_semanal_snacks**. Luego calculamos los cuantiles de esta nueva distribución y
los utilizamos para crear una nueva categorización: los individuos que tenga un ratio menor al
cuantil 2 tendran el valor **Bajo** y **Alto** en caso contrario. Se intento llevar a mas niveles
pero el test $T$ no daba significativo para todos los coeficientes del **modelo 2**.

1.  Definimos la districión altura/edad por categoria de **consumo_semanal_snacks**:

```{r fig.height=2, fig.width=4, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>% 
  mutate(alt_edad_ratio = round(altura/edad, 0))

avg_train_set_snack_2 <- train_set_snack_2 %>% 
   group_by(consumo_semanal_snacks) %>% 
   summarise(avg_alt_edad_ratio = mean(alt_edad_ratio))

ggplot(data = avg_train_set_snack_2, aes(x = avg_alt_edad_ratio)) + 
  geom_boxplot(alpha = 0.75, fill="blue") +
  theme_bw()
```

Se los siguientes cuantiles utilizaremos el cuantil 2(50%):

```{r}
quantiles_avg_alt_edad_ratio <- quantile(avg_train_set_snack_2$avg_alt_edad_ratio)
quantiles_avg_alt_edad_ratio
```

2.  Creamos un dataset intermedio donde estan mapeadas las categorias originales vs las nuevas:

```{r}
q2 <- quantiles_avg_alt_edad_ratio[3]

snack_level_mapping <- avg_train_set_snack_2 %>% 
  mutate(level = case_when(
    avg_alt_edad_ratio < q2  ~ 'Bajo',
    avg_alt_edad_ratio >=  q2 ~ 'Alto'
  )) %>% select(consumo_semanal_snacks, level)

snack_level_mapping %>%
  arrange(consumo_semanal_snacks)
```

3.  Creamos nuevos dataset de trasin/test con la nueva definición de la variable
    **consumo_semanal_snacks**:

```{r fig.height=4, fig.width=5, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)

test_set_snack_2 <- test_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)
```

```{r warning=FALSE}
train_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()

test_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()
```

4.  Evaluamos el nuevo train_set con el **modelo 2**:

```{r}
model_2_redefinicion_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_2
)

coefficients_summary(model_2_redefinicion_2)
anova_summary(model_2_redefinicion_2)
glance(model_2_redefinicion_2)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
models <- list(
  'Modelo 1' = model_1, 
  'Modelo 2' = model_2, 
  'Modelo 2 - Re-definición 1' = model_2_redefinicion_1, 
  'Modelo 2 - Re-definición 2' = model_2_redefinicion_2
)

models %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

**Conclusión**: Ambos modelos son significativos para explicar el peso. El modelo **Modelo 2 -
Re-definición 1** es mas explicativo, ya que $R^2$ ajustado es mayor. Finamente, ambos modelos son
meno explicativos que el modelo original(**Modelo 2**).

## 4. Modelos propios y evaluación

### 4.1. Realizar 2 modelos lineales múltiples adicionales y explicar breve-mente la lógica detrás de los mismos (se valorará la creación y/o inclusión de variables nuevas). Evaluar la performance del modelo inicial, el modelo categóricas con las categorías redefinidas de la variable consumo_semanal_snacks y los modelos desarrollados en este punto en el dataset de entrenamiento y evaluación (usar dataset "encuesta_salud_test.csv"). La evaluación de performance consiste en comparar en ambos sets la performance en términos del R cuadrado ajustado, RMSE y MAE.

Al continuación se define 2 modelos.

**Modelo 4**

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * diasActividadFisicaSemanal + \beta_6 * altura * genero$

Se utilizo la redefinición de la variable **consumo_semanal_snacks** como base. Ademase se agregar
la variable dias_actividad_fisica_semanal entendiendo que tiene una influencia iportante en el peso
y luego la asociacion altura \* genero ya que en general mas mujeres tienen a ser mas bajar que los
varones y vise versa.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_4 <- lm(
  peso~ 
    altura + 
    edad + 
    genero + 
    consumo_semanal_snacks +
    dias_actividad_fisica_semanal +
    altura*genero,
  data = train_set_snack_1
)

coefficients_summary(model_4)
anova_summary(model_4)
glance(model_4)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
train_set3 <- column_mean_quantile_binning(train_set_snack_1, 'dias_actividad_fisica_semanal')
test_set3  <- column_mean_quantile_binning(train_set_snack_1,  'dias_actividad_fisica_semanal')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_frutas')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_frutas')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_verdura')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_verdura')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_comida_grasa')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_comida_grasa')

train_set3 <- column_mean_quantile_binning(train_set3, 'consumo_semanal_gaseosas')
test_set3  <- column_mean_quantile_binning(test_set3,  'consumo_semanal_gaseosas')

segmented_box_plot(
  test_set3, 
  column        = 'peso', 
  segmented_by  = 'dias_actividad_fisica_semanal',
  title         = 'Niveles actividad fisica ordenados por la mediana del peso en Test',
  y_label       = 'Peso (Kg)',
  y_limits      = c(40, 100),
  x_label       = 'Niveles de actividad física (Dias)'
)
```

**Modelo 5**

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \\ \beta_5 * diasActividadFisicaSemanal + \beta_6 * consumoSemanalFrutas + \beta_7 * consumoSemanalVerduras + \\* \beta_8 * consumoSemanalGrasas + \beta_9 * consumoSemanalGaseosas$

Se utilizo la redefinición de la variable **consumo_semanal_snacks** como base. Ademase se agregar
la variable consumo_semenal_frutras/verduras/grasas/gaseaosas entendiendo que también tiene una
influencia importante en el peso.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_5 <- lm(
  peso ~ 
  edad +
  genero +
  altura +
  consumo_semanal_snacks +
  consumo_semanal_frutas + 
  consumo_semanal_verdura,
  data = train_set3
)

coefficients_summary(model_5)
anova_summary(model_5)
glance(model_5)
```

```{r}
c(models, list('Modelo 4'=model_4, 'Modelo 5'=model_5)) %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

Finalmente, si comparamos los modelos por $R^2$ Ajustado, se puede apreciar que el modelo 5 (con
todas las variables categóricas re-definidas) llega a captar la mayor varianza explicada sobre el
dataset de entrenamiento. Por supuesto esto no dice nada acerca de la performance del modelo en
test, pero si que tiene la mejor capacidad para extraer información de los dato de entrenamiento.

### 4.2. ¿Cuál es el mejor modelo para nuestro objetivo de predecir el peso? ¿Por qué?

Ahora comparamos la performance de todo los modelos al evaluar el error delos mismo al predecir el
peso en el conjunto de train y test tanto para RMSE como MAE:

**RMSE**

```{r fig.align='center', warning=FALSE}
custom_models_evaluation_summary(
  model_1, model_2, model_2_redefinicion_1, model_4, model_5,
  test_set, train_set_snack_1, test_set3,
  metric_fn = rmse
)
```

Si utilizamos la métrica RMSE podemos ver que el modelo 5 tiene el menor error en el conjunto de
test. Por otro lados el que tiene la mayor diferencia de error entre test y entrenamiento. Esto nos
dice que podría estar sobre-ajustandose al conjunto de entrenamiento. El modelo 3 tiene un error en
test muy cercano y ademas tiene un diferencia entre test y train mucho menor. por esto ultimo parece
ser el mejor modelo ya que tiene prácticamente el menor error posible y también el menor
sobre-ajuste al conjunto de entrenamiento.

**MAE**

```{r warning=FALSE}
custom_models_evaluation_summary(
  model_1, model_2, model_2_redefinicion_1, model_4, model_5,
  test_set, train_set_snack_1, test_set3,
  metric_fn = mae
)
```

Si medimos a partir del MAE sucede algo muy similar, El modelo 3 es es que tiene menor error y
ademas menos sobre-ajuste.

Finalmente, según ambas metricas el moejor modelo es el **Modelo 3**.

## 5. Diagnóstico del modelo

Analizar en profundidad el cumplimiento de los supuestos del modelo lineal para el modelo inicial.

```{r fig.height=4, fig.width=6, warning=FALSE, fig.align='center'}
plot(model_1)
```

**Homocedasticidad**

Al visualizar el primer gráfico (Residuos vs. Valores ajustados) se puede apreciar que hay presencia
de homocedasticidad, ya que a medida que aumentan los valores predichos la variabilidad o amplitud
de los residuos parece mantenerse en los mismo niveles. Dadas esta condiciones podemos decir que se
cumple el supuesto de varianza constante.

**Normalidad**

Al visualizar el diagrama **QQ-Plot** podemos observas que en el extremo derecho, el modelo
sobre-estima el peso del los individuos ya que hay una gran diferencia entre los valores predichos y
los valores esperados teóricos. Lo contrario sucede a izquierda, donde el modelo subestima el valor
de peso en comparación al valor esperado teórico, aunque los valores de los residuos son menores en
este caso. Finalmente el QQ-Plot muestra un grado de alejamiento pronunciado de una distribución
normal teórica y por lo tanto no se cumple el supuesto de normalidad del modelo.

**Apalancamiento (Leverage)**

Si observamos el gráfico de **Residuos vs Apalacamiento** vemos varias observaciones o individuos
que se alejan a derecha del cumulo principal. Estos ejercen un alejamiento de las prediciones del
modelo vs los valores reales a partir de un apalancamiento(leverage) 0.0025 y es mas pronunciado
desde 0.0035. Finalmente, vemos un grado importante de desvió de las predicciones vs valores reales
y porn ente un grado importante de apalancamiento(leverage).

A continuación se pueden ver lo individuos que producen mayor apalancamiento(leverage) y por ende
sesgo en las predicciones del modelo:

```{r}
augment(model_1) %>%
  filter(.hat>0.0025) %>%
  arrange(.hat)
```

## 6. Modelo Robusto

Leer el archivo "encuesta_salud_modelo6.csv". Este último consiste en el dataset original de train
con la incorporación de algunas observaciones adicionales que pueden incluir valores atípicos. En
particular, observar la relación entre peso y altura ¿Qué ocurre con estos nuevos datos? Entrenar el
modelo inicial con estos nuevos datos y comentar qué se observa en los coeficientes estimados y las
métricas de evaluación (R cuadrado ajustado, RMSE y MAE) respecto al modelo entrenado con el set de
entrenamiento original. Entrenar un modelo robusto con la misma especificación que el modelo inicial
sobre los nuevos datos. Comparar los coeficientes y su performance (RMSE y MAE) respecto al modelo
inicial no robusto entrenado en este punto. ¿Qué puede concluir al respecto?

Se carga el conjunto de entrenamiento en crudo,e s decir sin pre-procesamiento. Luego se resumen los
valores de las variables categóricas y se eliminan missing values, ya que siguen siendo muy poco
casos:

```{r warning=FALSE}
original_train_set <- shorten_values(preprocess(load_original_train_set()))
missings_summary(original_train_set)
new_train_set <- process_missings(original_train_set)
missings_summary(new_train_set)
```

```{r}
nrow(original_train_set)
nrow(new_train_set)
```

Comparemos las distribuciones del peso vs altura en ambos conjunto de entrenamiento:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
box_plots(
  train_set %>% select(peso, altura), 
  title = 'Comparativas de distribuciones del peso y la altura'
)

box_plots(
  new_train_set %>% select(peso, altura), 
  title = 'Comparativas de distribuciones del peso y la altura'
)
```

En el dataset de entrenamiento original la variable peso tiene prácticamente el doble de outliers
que el dataset procesado.

**Modelo 6**

Definimos un modelo igual al **modelo 1** pero entrenando en el dataset de entrenamiento original.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_6 <- lm(
  peso ~ altura + edad + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = new_train_set
)

coefficients_summary(model_6)
anova_summary(model_6)
glance(model_6)
```

```{r}
print(paste('Disminicion de adj.r.squared:', abs(0.352113 - 0.2734821) * 100, '%'))
```

Dada la presencia de outliers en la variable peso, el $R^2$ Ajustado baja con respecto al **modelo
1**.

```{r}
models <- list('Modelo 6'=model_6)

models_evaluation_summary(models, train_set, metric_fn = rmse)
models_evaluation_summary(models, train_set, metric_fn = mae)
```

Por otro lado, aumento el error de predicción tanto en train como en test. Finalmente, el modelo
tiene un grado de overfitting mucho mayor que los modelos anteriores, ya que la métrica de
evaluación en test y train tiene una diferencia muy pronunciada de 1.7 puntos.

**Modelo 7**

Definimos un modelo igual al **modelo 1** entrenando en el dataset de entrenamiento original y
usamos un modelo lineal robusto.

```{r}
model_7 <- rlm(
  peso ~ altura + edad + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = new_train_set
)
coefficients_summary(model_7)
```

```{r}
anova_summary(model_7)
```

```{r}
models <- list('Modelo 6'=model_6, 'Modelo 7'=model_7)

models_evaluation_summary(models, test_set, metric_fn = rmse)
models_evaluation_summary(models, test_set, metric_fn = mae)
```

El modelo lineal robusto (Modelo 7) parece tener un menor error de entrenamiento muy cercano al
modelo 6, pero tiene mayor sobre- ajuste que el modelo 6, aunque es una diferencia muy baja.

Dado esto, seria una buena selecciono elegir el modelo 7, ya que el sobre ajuste practicamente no
cambia y obtenemos un error de predicción en test ligeramente menor.
