---
title: |
    | Maestría en Explotación de datos y Descubrimiento de conocimiento
    |
    |
    | Materia: Enfoque Estadistico del Aprendizaje
    | Trabajo práctico 1: Regresion Lineal (Parte 2)
author: "Adrian Norberto Marino"
date: "2021/09/19"
fig_width: 3 
fig_height: 3 
output:
  html_document:
    highlight: pygments
    theme: sandstone
    toc: yes
    df_print: paged
    includes:
      before_body: ./header.html
      after_body: ./footer.html
  html_notebook:
    toc: yes
    toc_float: yes
    df_print: paged
editor_options: 
  markdown: 
    wrap: 100
---

## 2. Modelo inicial

### 2.1. Se plantea la siguiente primera alternativa para modelar el peso:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * diasActividadFisicaSemanal + \beta5 * consumoDiarioAlcohol$

Primero se cargan las librerías necesarias:

```{r message=FALSE, warning=FALSE}
options(warn=-1)
rm(list=ls())
gc()
options(warn=-2)
```

```{r message=FALSE, warning=FALSE}
# install.packages("pacman") -- Descomentar par instalar pacman
library(pacman)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
import('../src/preprocessing.R')
import('../src/model.R')
import('../src/plot.R')
```
A continuación se carga los conjuntos de entrenamiento y test. También se resumen los valores de las
variables categóricas y transforman todo los valores faltantes a NA's ya que el modelo lineal los excluye 
por defecto. Fuera de esto tenemos muy pocos valores faltantes como ya analizamos en la notebook [eea-tp1-eda](https://rpubs.com/adrianmarino/eea-tp1-eda).

```{r message=FALSE, warning=FALSE}
train_set <- load_train_set() %>% 
  preprocess() %>% 
  shorten_values() %>%
  process_missings()

test_set <- load_test_set() %>% 
  preprocess() %>% 
  shorten_values() %>% 
  process_missings()
```

Validamos la estrutura de los datos:

```{r}
glimpse(train_set)
```

Las variables categóricas se transforman a factores ordinales o no ordinales según sea el caso.

A contunuación se fija la semilla y se validan las proporciones de los conjuntos de entrenamiento y test:

```{r}
set.seed(25)
show_train_test_props(train_set, test_set)
```

**Modelo 1**

Se plantea el primer modelo lineal:

```{r}
model_1 <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set
)
```

### 2.2. ¿Cuál es la interpretación de cada uno de los coeficientes estimados?

Veamos a continuación un resumen de los coeficiente del **modelo 1**:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_1)
```

Al analizar cada coeficiente se encuentra que:

-   $\hat{\beta_0}$ (Ordenada al origen) de valor -68.92 Kg, es el peso esperado o promedio de un
    individuo de genero femenino que tiene cero altura, edad, actividad física y consumo diario de
    alcohol. Esto no es interpretable, ya que una persona tiene que tener una altura superior a cero
    y no puede tener un peso negativo, pero si podría no realizar actividad física ni consumir
    alcohol.

-   El coeficiente $\hat{\beta_1}$ de valor 650 gramos, corresponde a la altura del individuo. Este
    coeficiente indica que dada una edad, genero, consumo de alcohol diario y días de actividad
    física semanal fijos, cada incremento en 1 cm adicional en la altura del individuo implica un
    aumento de su peso esperado o promedio de 650 gramos.

-   El coeficiente $\hat{\beta_2}$ de valor 1.4 kg, corresponde a la edad del individuo. Este
    coeficiente indica que dada una altura, genero, días de actividad física y consumo de alcohol
    diario fijos, cada vez que el individuo cumple un año su peso esperado o promedio aumenta en
    1.4 kg.

-   El coeficiente $\hat{\beta_3}$ de valor 1.26 kg, corresponde a los individuos de genero
    masculinos. Este coeficiente indica que dada una altura, edad, consumo de alcohol diario y días
    de actividad física semanal fijos, el peso promedio o esperado para el genero masculino es 1.26
    kg mayor al peso femenino (categoría basal). Por otro lado, el coeficientes nos indica cuanto mas
    alto es el peso del genero masculino respecto del femenino al fijar los demás coeficientes.

-   El coeficiente $\hat{\beta_4}$ de valor 87.1 gramos, corresponde a los días de actividad física
    semanal que realiza el individuo. Este coeficiente indica que dada una altura, edad, genero y
    consumo de alcohol diario fijos, cada vez que un individuo realiza un día mas de actividad física
    semanal su peso esperado o promedio disminuye en 87.1 gramos.

-   El coeficiente $\hat{\beta_5}$ de valor 7 gramos, corresponde al nivel de consumo diario de
    alcohol del individuo. Este coeficiente indica que dada una altura, edad, genero y días de
    actividad física semanal fijos, cada vez que el individuo consume un trago de alcohol su peso
    esperado o promedio aumenta en 8 gramos.

### 2.3. ¿Son significativos los coeficientes?

Para determina si los coeficientes son aptos para explicar el peso de un individuo se realiza un
${T}$ test para cada coeficiente en el cual se evalúan las siguientes hipótesis:

-   ${H_0: \beta_i = 0}$
-   ${H_1: \beta_i \neq 0}$

Si ${\beta_i \neq 0}$ podemos decir que existe una diferencia estadisticamente significativas del
cero para el coeficiente ${\beta_i}$, y por lo tanto el coeficiente ${\beta_i}$ explicar la variable
${y}$ (Peso en nuestro caso).

Luego analizando la salida de **coefficients_summary** concluimos que:

-   Los coeficientes correspondientes a la categoria basal ${\beta_1}$(Genero femenino),
    altura(${\beta_1}$), edad(${\beta_2}$) y genero masculino (${\beta_3}$) tienen $p-valor < 0.05$.
    Por lo tanto, se rechaza la hipótesis nula y resultan estadistitamente significativos para
    explicar el peso. Por otro lado, se puede apreciar que los intervalos de confianza del 95% no
    incluyen al cero.
-   Lo contrario sucede con días de actividad física semanal(${\beta_4}$) y consumo de alcohol
    diario (${\beta_5}$), dado que ambos no rechazar la hipótesis de nulidad ($p-valor > 0.05$) y por lo
    tanto no existe una diferencia significativa del cero. Finalmente, no hay evidencia
    estadistitamente significativas pensar que estos coeficientes expliquen el peso.

### 2.4. ¿El modelo resulta significativo para explicar el peso?

Para determinar si es modelo es significativo para explicar el peso de un individuo se realiza un
$F$ test con las siguientes hipótesis:

-   $H_0: {\beta_1} = {\beta_2} = · · · = {\beta_{p−1}} = 0$
-   $H_1:$ Por lo menos un ${\beta_k}$ ($k = 1, 2,..., p−1$) es distinto de 0.

Donde: 

- $H_0$ afirma que no hay vinculo entre la variable ${y}$(Peso) y las variables regresoras.
- $H_1$ afirma que al menos una de las variables regresoras sirve para predecir la variable ${y}$(Peso).

Veamos los resultados del $F$ test:

```{r}
glance(model_1)
```

Podemos apreciar que el $p-valor < 0.05$ y igual a 0. Con mucha certeza podemos decir que al menos
una de las variables regresoras permite explicar el peso. Esto concuerda con los resultados de los
$T$ test para los coeficientes correspondientes a altura, edad y genero femenino(basa) y masculino.

### 2.5. ¿Qué porcentaje de la variabilidad explica el modelo?

Según el valor de $R^2$ ajustado (**adj.r.squared**), este modelo llega a explica el 35.39% de la
variabilidad del dataset de entrenamiento, lo cuales un valor bajo pero tampoco es despreciable.

### 2.6. ¿Que sucede si ponemos al genero masculino como variable basal?

```{r}
train_set_genero <- data.frame(train_set) 
train_set_genero$genero <- factor(
  train_set_genero$genero,
  levels=c('Masculino', 'Femenino'), 
  ordered=FALSE
)
table(train_set_genero$genero)
```

```{r}
model_genero <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = train_set_genero
)
```

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_genero)
```

```{r}
glance(model_genero)
```

Observaciones:

-   En este caso, cambia el valor del coeficiente $\hat\beta_0$ para la categoría basal, manteniéndose los demás
    coeficientes.
-   Siguen siendo significativos los mismo coeficientes. La única diferencia es que $\hat\beta_0$(basal)
    representa al genero masculino y $\hat\beta_3$ al femenino.
-   Se mantiene la significatividad global del modelo y se obtiene el mismo $R^2$ ajustado.
-   Como ultimo, cabe aclarar que al cambiar la categoría basar cambian las interpretaciones del
    modelo.

## 3. Modelo categóricas

### 3.1. Se sugiere probar un modelo que incorpore el consumo semanal de snacks y una interacción entre el género y la edad, en lugar de actividad física y consumo de alcohol. Además se pide explicitamente que la categoría "No comí comida salada o snacks en los últimos 7 días" de la variable **consumo_semanal_snacks** se encuentre como nivel/categoría basal.

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \beta4 * consumoSemanalSnacks + \beta_5 * genero * edad$

Primero validamos que las primeras categorías en cada variable de tipo factor sean las correctas, ya
que esta sera la que el modelo defina como categoría basal:

```{r}
table(train_set$consumo_semanal_snacks)
table(train_set$genero)
```

Se puede apreciar que la primeras categorías corresponden a 0 consumo de snacks semanal y genero
femenino. Por otro lado la categoría genero se encuentra balanceada en gran medida.

A continuación se cambiar la variable factor a no ordenada para que aparezcan correctamente valores de las categorías en los coeficientes:

```{r}
train_set_model_1 <- train_set 

train_set_model_1$consumo_semanal_snacks <- factor(
  train_set_model_1$consumo_semanal_snacks,
  levels=c("0", "<=3", "4-6", "7", "14", "21", ">=28"), 
  ordered=FALSE
)
```


**Modelo 2**

Definimos el nuevo modelo:

```{r}
model_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_model_1
)
```

### 3.2. ¿Cuál es la interpretación de los coeficientes estimados para las categorías de consumo_semanal_snacks y genero * edad? ¿Son significativas?

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
coefficients_summary(model_2, show_tidy_sumamry = FALSE)
```

Si interpretamos los coeficientes que son significativos para el $T$ test:

1.  Coeficiente correspondiente al **consumo_semanal_snacks<=3**: Si fijamos los coeficientes correspondientes a la altura, edad, generoMasculino y edad:generoMasculino; el peso promedio o esperado de un individuo de consume snacks hasta 3 veces por semana es 1.33 kg menor que aquellos que no consumen snacks.

2.  Sucede algo similar con las categorías **consumo_semanal_snacks4-6** y
    **consumo_semanal_snacks>=28** donde:

-   El peso para un individuo que consume de 4 a 6 veces por semana es 2.26 kg menor que aquellos
    que no consumen snacks.
-   El peso para un individuo que consume 28 veces a mas por semana es 2.56 kg menor que aquellos que
    no consumen snacks. 

Puede parecer contradictorio que os que mas consumen snacks menos pesan, pero pensemos que no tenemos desglose de esta categorías. Hoy en día se consumen muchos snacks saludables, los cuales no tienen grasas, pero también existen los tradicionales ricos en grasas como papas fritas, palitos con queso, 3D, etc. 
Según los coeficientes que obtuvimos con este dataset, se podría pensar que los individuos están consumiendo
en mayor medida snacks saludables, pero solo podemos asegurarlo si incluimos la variables tipo de snack.

3.  Coeficiente correspondiente al **edad * genero**:

Dado el modelo original:

$E(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_3 * genero + \ \beta4 * consumoSemanalSnacks + \beta_{2,3} * genero * edad$

y sabiendo que el genero femenino toma el valor 0 y masculino 1. Si reemplazamos estos valores en el
modelo original encontramos que:

$E_f(peso) = \beta_0 + \beta_1 * altura + \beta_2 * edad + \beta_4 * consumoSemanalSnacks$

El genero femenino tiene la ordenada $\beta0$ y las pendientes determinada por $\beta_1$, $\beta_2$
y $\beta_4$.

$E_m(peso) = (\beta_0 + \beta_3) + \beta_1 * altura + (\beta_2 + \beta_{2,3}) * edad + \ \beta_4 * consumoSemanalSnacks$

El genero masculino tiene una ordenada que es la suma de la ordenada del genero femenino $\beta_0$
mas $\beta_3$. Tambien cambia la pendiente de $\beta_2$ de la edad, a la cual se le suma $\beta_{2,3}$.

Ahora, si solo cambian los coeficientes correspondientes al genero y edad, es decir si mantenemos
contantes los demás coeficientes obtenemos:

-   $E_f(peso) = \beta_0 + \beta_2 * edad + cte$
-   $E_m(peso) = (\beta_0 + \beta_3) + (\beta_2 + \beta_{2,3}) * edad$

Reemplazamos por los coeficientes por lo valores que encontró el modelo:

-   Femenino:

    -   $E_f(peso) = -64.2548500 + 1.2253900 * edad + cte$

-   Masculino:

    1.  $E_m(peso) = (-64.2548500 +  -4.6046463) + (1.2253900 + 0.3892757) * edad + cte$
    2.  $E_m(peso) = -68.8595 + 1.614666 * edad + cte$

Finalmente tenemos:

- $E_f(peso) = -64.2548500 + 1.2253900 * edad + cte$
- $E_m(peso) = -68.8595 + 1.614666 * edad + cte$


Finalmente, graficamos ambas rectas definiendo la $cte$ con un valor que de pesos positivos para
tener una gráfica consistente:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
cte = 100

train_set %>% 
  mutate(
    peso = ifelse(
      genero=='Femenino', 
      (-64.2548500 + 1.2253900 * edad) + cte,
      (-68.8595 + 1.614666 * edad) + cte
    ) 
  ) %>%
  ggplot(aes(x = edad, y = peso, colour=genero)) +
  geom_line() +
  ylab('Peso') +
  xlab('Edad')
```

Finalmente, se puede apreciar que las ordenadas de ambos géneros son distintas, donde el genero
femenino inicia desde un peso 4kg menor al masculino. Luego si variamos únicamente la edad, se aprecia
que el peso del genero masculino es mayor al femenino para la misma edad en todo los casos. Esto se
debe a que la recta correspondiente al genero masculina esta por arriba de la resta correspondiente
al genero femenino.

### 3.3. ¿Qué porcentaje de la variabilidad explica el modelo? En caso de detectar que existen categorías no significativas de la variable consumo_semanal_snacks evaluar si la variable es significativa en su conjunto y, en caso afirmativo, proponer una redefinición de las mismas que permita obtener una mayor proporción de categorías significativas individualmente. Luego, analizar si existen cambios en la variabilidad explicada por el modelo.

Viendo el resultado de **coefficients_summary** se aprecia que las siguientes categorías de
**consumo_semanal_snacks** no son significativas:

-   2 veces al día (14 veces/semana).
-   4 a 6 veces durante los últimos 7 (4 a 6 veces/semana).
-   3 veces al día (21 veces/semana).

Pero si son significativos los extremos:

-   De 1 a 3 veces/semana.
-   De 28 o mas veces/semana.

A continuación se realiza un $F$ test para evaluar la significatividad conjunta de las categóricas
de la variable **consumo_semanal_snacks** para explicar el peso.

El $F$ test también llamando ANOVA (Análisis de la varianza) se realiza para probar la
significatividad conjunta de todos los valores de una variable categórica.

Las hipótesis son las siguientes:

-   $H_0: β_q = β_{q+1} = · · · = β_{p−1} = 0$
-   $H_1:$ por lo menos uno de los $β_k$ (con $k$ entre $q$ y $p−1$) es tal que $β_k \neq 0$.

Luego si todos los coeficientes asociados a los valores de variable categórica son cero, se rechaza
la hipótesis nula y por lo tanto la variable no es significartiva para explicar el peso en nuestro
caso.

A continuación veremos el p-valor resultado de aplicar $F$ test para cada variable del modelo:

```{r}
anova_summary(model_2)
```

Podemos apreciar que el $p-value < 0.005$ para la variable **consumo_semanal_snacks**. Por lo tanto
se rechaza la hipótesis nula y podemos decir que en su conjunto resulta estadísticamente significativa
para explicar el peso. Luego, como la variable **consumo_semanal_snacks** es significativa vale la
pena re-definirla. 
Por otro lado, la combinación de variables genero-edad no es estadísticamente significativa para explicar 
el peso, pero si lo es el genero en forma separada. Finalmente, como ya vimos en pasos anteriores, edad y 
altura son significativas.

**Modelo 2: Redefinición 1**

Dado que no todas las categorías de la variable **consumo_semanal_snacks** son significativas, a
continuación se propone una re-definición, en la que se reagrupan las categorías en nuevas categorías 
que si resulten significativas para el **modelo 2**:

```{r}
train_set_snack_1 <- train_set %>% mutate(consumo_semanal_snacks = case_when(
  consumo_semanal_snacks %in% c('<=3', '4-6' , '7')  ~ '<=7',
  consumo_semanal_snacks %in% c('14', '21', '>=28')  ~ '>=14',
  TRUE ~ as.character(consumo_semanal_snacks)
))
train_set_snack_1$consumo_semanal_snacks <- factor(
  train_set_snack_1$consumo_semanal_snacks,
  levels=c('0', '<=7', '>=14'),
  ordered=FALSE
)

test_set_snack_1 <- test_set %>% mutate(consumo_semanal_snacks = case_when(
  consumo_semanal_snacks %in% c('<=3', '4-6' , '7')  ~ '<=7',
  consumo_semanal_snacks %in% c('14', '21', '>=28')  ~ '>=14',
  TRUE ~ as.character(consumo_semanal_snacks)
))

table(train_set_snack_1$consumo_semanal_snacks)
table(test_set_snack_1$consumo_semanal_snacks) 
```

Como se puede ver, se reagruparan las categorías en 3 grupos:

- 0 veces/semana.
- Hasta 7 veces/semana.
- Mas de 14 veces/semana.

Luego entrenamos el **Modelo 2** usnado esta nueva re-definición:

```{r}
model_2_redefinicion_1 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_1
)

coefficients_summary(model_2_redefinicion_1)
anova_summary(model_2_redefinicion_1)
glance(model_2_redefinicion_1)
```

**Modelo 2: Redefinición 2**

En este caso se propone calcular la media del ratio **altura/edad** para cada categoría de la
variables **consumo_semanal_snacks**. Luego calculamos los cuantiles de esta nueva distribución y
los utilizamos para crear una nueva categorización: Los individuos que tenga un ratio menor al
cuantíl 2 (Mediana) tendran el valor **Bajo** y **Alto** en caso contrario. Se intento llevar a mas niveles 
pero el test $T$ no daba significativo para todos los coeficientes.

1.  Definimos la districión altura/edad por categoria de **consumo_semanal_snacks**:

```{r fig.height=2, fig.width=4, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>% 
  mutate(alt_edad_ratio = round(altura/edad, 0))

avg_train_set_snack_2 <- train_set_snack_2 %>% 
   group_by(consumo_semanal_snacks) %>% 
   summarise(avg_alt_edad_ratio = mean(alt_edad_ratio))

ggplot(data = avg_train_set_snack_2, aes(x = avg_alt_edad_ratio)) + 
  geom_boxplot(alpha = 0.75, fill="blue") +
  theme_bw()
```

DE los siguientes cuantíles utilizaremos el cuantíl 2(Mediana o 50%):

```{r}
quantiles_avg_alt_edad_ratio <- quantile(avg_train_set_snack_2$avg_alt_edad_ratio)
quantiles_avg_alt_edad_ratio
```

2.  Creamos un dataset intermedio donde están mapeadas las categorias originales vs las nuevas:

```{r}
q2 <- quantiles_avg_alt_edad_ratio[3]

snack_level_mapping <- avg_train_set_snack_2 %>% 
  mutate(level = case_when(
    avg_alt_edad_ratio < q2  ~ 'Bajo',
    avg_alt_edad_ratio >=  q2 ~ 'Alto'
  )) %>% select(consumo_semanal_snacks, level)

snack_level_mapping %>%
  arrange(consumo_semanal_snacks)
```

3.  Creamos nuevos dataset de train/test con la re-definición de la variable **consumo_semanal_snacks**:

```{r fig.height=4, fig.width=5, warning=FALSE, fig.align='center'}
train_set_snack_2 <- train_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)

test_set_snack_2 <- test_set %>%
  inner_join(snack_level_mapping, by = 'consumo_semanal_snacks') %>%
  mutate(consumo_semanal_snacks = level) %>% 
  select(-level)
```

```{r warning=FALSE}
train_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()

test_set_snack_2 %>%  
  group_by(consumo_semanal_snacks) %>% 
  tally()
```

4.  Evaluamos el nuevo train_set con el **modelo 2**:

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_2_redefinicion_2 <- lm(
  peso ~ altura + edad + genero + consumo_semanal_snacks +  genero * edad, 
  data = train_set_snack_2
)

coefficients_summary(model_2_redefinicion_2)
anova_summary(model_2_redefinicion_2)
glance(model_2_redefinicion_2)
```

**Conclusión**

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
models <- list(
  'Modelo 1' = model_1, 
  'Modelo 2' = model_2, 
  'Modelo 2 - Re-definición 1' = model_2_redefinicion_1, 
  'Modelo 2 - Re-definición 2' = model_2_redefinicion_2
)

models %>% 
  map_df(glance, .id = "model") %>%
  arrange(desc(adj.r.squared))
```

Ambos modelos son significativos para explicar el peso. El modelo **Modelo 2 - Re-definición 1** 
es mas explicativo,  ya que $R^2$ ajustado es mayor par este dataset de entrenamiento. Por otro lado, 
ambos modelos son menos explicativos que el **Modelo 2** pero mas explicativos que el 
**Modelo 1** (inicial). Finalmente es importante apreciar que las diferencian del $R^2$ ajustado son muy bajas 
entre los modelos, deberiamos evaluarlo en test para entnder cual modelo podria performar menor.

## 4. Modelos propios y evaluación

### 4.1. Realizar 2 modelos lineales múltiples adicionales y explicar breve-mente la lógica detrás de los mismos (se valorará la creación y/o inclusión de variables nuevas). 

Al continuación se define 2 modelos.

**Modelo 3**

En base a los resultados de importancia de variables realizados en la notebook [eea-tp1-eda](https://rpubs.com/adrianmarino/eea-tp1-eda), $R^2$ ajustado de los resultados y la significación de los coeficientes se seleccionaron las siguientes variables:

* Altura: Ya que la altura influye en el peso del individuo directamente.
* Genero: No tiene un relación directa, pero lo individuos masculinos tienden a tener mas altura y por ende mayor peso.
* consumo_semanal_snacks y consumo_semanal_comida_grasa: Puede considerarse que estas variables afectan en gran media al aumento de peso.
* altura * edad: Ya que existe una relación importante entre la edad y la altura en el rango de edades del dataset (12 a 18 años). Esta relación se entiende que afecta al peso al igual que la altura. 
*  altura * genero: Parece haber una relación definida entre la altura y el genero, ya que al agregar esta variable
aumenta ligeramente el $R^2$ Ajustado.


```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_3 <- lm(
  peso~ 
    altura + 
    genero + 
    consumo_semanal_snacks +
    consumo_semanal_comida_grasa + 
    altura * edad + 
    altura * genero,
  data = train_set
)

coefficients_summary(model_3)
anova_summary(model_3)
glance(model_3)
varImp(model_3)
```

**Modelo 4**

En este modelo principalmente se busco sumar explicabilidad al modelo, es decir el mayor $R^2$ ajustado posible sin
prestar atención si las variables son explicativas o sus categorìas en caso de ser categòricas. Para esto
se agregaron todas las variables del train_set y luego quellas combinaciòn que sumaron $R^2$ en el *modelo 3*.

```{r fig.height=7, fig.width=6, warning=FALSE, fig.align='center'}
model_4 <- lm(
  peso ~
  edad +
  genero +
  nivel_educativo + 
  altura + 
  frecuencia_hambre_mensual + 
  dias_consumo_comida_rapida +
  edad_consumo_alcohol + 
  consumo_diario_alcohol + 
  dias_actividad_fisica_semanal +
  consumo_semanal_frutas +
  consumo_semanal_verdura +
  consumo_semanal_gaseosas +
  consumo_semanal_snacks +
  consumo_semanal_comida_grasa +
  altura * edad + 
  altura * genero + 
  altura * nivel_educativo,
  data = train_set
)

coefficients_summary(model_4, show_tidy_sumamry = FALSE)
anova_summary(model_4)
glance(model_4)
```

Finalmente, si comparamos los modelos por $R^2$ Ajustado, se puede apreciar que el **Modelo 4** llega
a captar la mayor varianza explicada sobre el conjunto de entrenamiento. Por supuesto esto no dice
nada acerca de la performance del modelo en test, pero si que tiene la mejor capacidad para extraer
información de los dato de entrenamiento.

### 4.2. Evaluar la performance del modelo inicial, el modelo con las categorías redefinidas de la variable consumo_semanal_snacks y los modelos desarrollados en este punto en el dataset de entrenamiento y evaluación (usar dataset "encuesta_salud_test.csv"). La evaluación de performance consiste en comparar en ambos sets la performance en términos del R cuadrado ajustado, RMSE y MAE ¿Cuál es el mejor modelo para nuestro objetivo de predecir el peso? ¿Por qué?

Ahora comparamos la performance de todo los modelos evaliando el error de los mismo al predecir el
peso en el conjunto de train y test tanto para RMSE como MAE:


**RMSE**

```{r}
eval_summary <- function(metric_fn = rmse) {
  summary_part_1 <- list(
    'Modelo 1' = model_1, 
    'Modelo 2' = model_2, 
    'Modelo 3' = model_3,
    'Modelo 4' = model_4
  ) %>% train_test_eval_metric_summary(test_set = test_set, metric_fn = metric_fn)
  
  summary_part_2 <- list('Modelo 2 - Re-definición 1' = model_2_redefinicion_1) %>% 
    train_test_eval_metric_summary(test_set = test_set_snack_1, metric_fn = metric_fn)
  
  summary_part_3 <- list('Modelo 2 - Re-definición 2' = model_2_redefinicion_2) %>% 
    train_test_eval_metric_summary(test_set = test_set_snack_2, metric_fn = metric_fn)

  summary <- summary_part_1 %>% 
    union_all(summary_part_2) %>% 
    union_all(summary_part_3)
  
  min_test_error <- summary %>% 
    pull(test_error) %>% 
    min()
  
  max_r_2_adjusted <- summary %>% 
    pull(r_2_adjusted) %>% 
    max()

  summary %>% mutate(
    min_test_error_diff = abs(test_error - min_test_error),
    max_r2_diff         = abs(r_2_adjusted - max_r_2_adjusted)
  ) %>%
    select(model, r_2_adjusted, max_r2_diff, train_error , test_error, error_diff, min_test_error_diff) %>%
    arrange(test_error)
}

rmse_eval_summary_result <- eval_summary(rmse)
rmse_eval_summary_result
```

Si utilizamos la métrica RMSE podemos ver que el modelo **Modelo 2 - Re-definición 1** tiene el menor error
al evaluarlo con el conjunto de test. Por otro lado, es el que tiene menor diferencia de error entre test
y entrenamiento. Esto nos dice que tiene el menor grado de sobre-ajuste (overfitting) al conjunto de 
entrenamiento. 
Otro punto importante, es que es uno de los modelos con mayor diferencian en $R^2$ ajustado 
contra el **Modelo 4** el cual tiene el mayor $R^2$ ajustado, siendo este es otro indicador de que el 
**Modelo 4** se ajusta mas al conjunto de entrenamiento, cayendo en el mayor sobre ajuste posible.
Sucede algo muy similar con el modelo **Modelo 3** pero en menor medida es cual es el segundo sobre ajustando
y el que tiene mayor error al evaluar en test seguido de los modelos 1 y 4.

**MAE**

```{r warning=FALSE}
mae_eval_summary_result <- eval_summary(mae)
mae_eval_summary_result
```

Usan la métrica MAE el **Modelo 4** es el que tiene el menor error en test seguido de **Modelo 2 - Re-definición 1**.
El **Modelo 2 - Re-definición 1** parece ser el modelo que menos sobre-ajuste y sorprendente-mente el **Modelo 4** a pesar de ser el que menos error tiene el test también es el que mas sobre ajusta al conjunto de test dado. Por esta ultima cuestión
la mejor opción es el modelo **Modelo 2 - Re-definición 1** ya que el modelo **Modelo 4** es el que peor generaliza.

Finalmente, según ambas métricas **Modelo 2 - Re-definición 1** es el modelo mas adecuado para ambas metricas (RMSE y MAE).


## 5. Diagnóstico del modelo

Analizar en profundidad el cumplimiento de los supuestos del modelo lineal para el modelo inicial.

```{r fig.height=4, fig.width=6, warning=FALSE, fig.align='center'}
plot(model_1)
```

**Homocedasticidad**

Al visualizar el primer gráfico (Residuos vs. Valores ajustados) se puede apreciar que hay presencia
de homocedasticidad, ya que a medida que aumentan los valores predichos la variabilidad o amplitud
de los residuos parece mantenerse en los mismo niveles. Dadas esta condiciones podemos decir que se
cumple el supuesto de varianza constante.

**Normalidad**

Al visualizar el diagrama **QQ-Plot** podemos observas que en el extremo derecho, el modelo
sobre-estima el peso del los individuos ya que hay una gran diferencia entre los valores predichos y
los valores esperados teóricos. Lo contrario sucede a izquierda, donde el modelo subestima el valor
de peso en comparación al valor esperado teórico, aunque los valores de los residuos son menores en
este caso. Finalmente el QQ-Plot muestra un grado de alejamiento pronunciado de una distribución
normal teórica y por lo tanto no se cumple el supuesto de normalidad del modelo.

**Apalancamiento (Leverage)**

Si observamos el gráfico de **Residuos vs Apalacamiento** vemos varias observaciones o individuos
que se alejan a derecha del cumulo principal. Estos ejercen un alejamiento de las prediciones del
modelo vs los valores reales a partir de un apalancamiento(leverage) 0.0025 y es mas pronunciado
desde 0.0035. Finalmente, vemos un grado importante de desvió de las predicciones vs valores reales
y por ente un grado importante de apalancamiento(leverage).

A continuación se pueden ver lo individuos que producen mayor apalancamiento(leverage) y por ende
sesgo en las predicciones del modelo:

```{r}
augment(model_1) %>%
  filter(.hat>0.0025) %>%
  arrange(.hat)
```

## 6. Modelo Robusto

### 6.1. Leer el archivo "encuesta_salud_modelo6.csv". Este último consiste en el dataset original de train
con la incorporación de algunas observaciones adicionales que pueden incluir valores atípicos. En
particular, observar la relación entre peso y altura ¿Qué ocurre con estos nuevos datos?

A continuación se carga el conjunto de entrenamiento en crudo, es decir sin pre-procesamiento. Luego
se resumen los valores de las variables categóricas y se transforman lo misssings a NA's:

```{r warning=FALSE}
original_train_set <- load_original_train_set() %>% 
  preprocess() %>% 
  shorten_values() %>% 
  process_missings()

original_train_set %>% missings_summary()
```

Se aprecia que hay muy pocos missing values. Por otro lado estos no se eliminan ya que el modelo
lineal por defecto los filtra. Comparemos las distribuciones del peso vs. altura en ambos conjunto
de entrenamiento:

```{r fig.height=5, fig.width=4, warning=FALSE, fig.align='center'}
box_plots(train_set %>% select(peso, altura), title = 'Peso vs. Altura en train')
box_plots(original_train_set %>% select(peso, altura), title = 'Peso vs. Altura en train(Original)')
```

En el dataset de entrenamiento original la variable peso tiene prácticamente el doble de outliers
que el dataset procesado.


### 6.2. Entrenar el modelo inicial con estos nuevos datos y comentar qué se observa en los coeficientes 
estimados y las métricas de evaluación (R cuadrado ajustado, RMSE y MAE) respecto al modelo entrenado 
con el set de entrenamiento original.

**Modelo 5**

Definimos un modelo igual al **modelo 1** pero entrenando en el dataset de entrenamiento original.

```{r fig.height=3, fig.width=6, warning=FALSE, fig.align='center'}
model_5 <- lm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = original_train_set
)

coefficients_summary(model_5, show_tidy_sumamry = FALSE)
anova_summary(model_5)
glance(model_5)
```

```{r}
compare_r2(model_1, model_5)
```

Hay una diferencia porcentual muy alta del $R^2$ ajustado en ambos modelos. El hecho de que existan outliers 
en el conjunto de entrenamiento original produce que disminuya la explicabilidad del mismo.


```{r}
models <- list('Modelo 1' = model_1, 'Modelo 5' = model_5)
models %>% eval_models_summary(test_set,  metric_fn = rmse)
models %>% eval_models_summary(test_set,  metric_fn = mae)
```

En este caso los resultados son muy consistentes con ambas métricas (RMSE y MAE). En ambos caso el 
**Modelo 1** es el que logra un menor error en test, ademas de tener la menor diferencia entre train y test.
Por otro lado, con ambas métricas se aprecia que el **Modelo 5** tiene peor performance en train que en test.
Esto podría deberse a que el modelo tiene ejemplos mas difíciles de ajustar en train que en test, ya sea por 
efecto de los outliers o por que existe algún ejemplo extra el cual es difícil de ajustar para el modelo.
A pesar de esto, hay muy poca diferencia de error en test entre ambos modelos.

### 6.3. Entrenar un modelo robusto con la misma especificación que el modelo inicial
sobre los nuevos datos. Comparar los coeficientes y su performance (RMSE y MAE) respecto al modelo
inicial no robusto entrenado en este punto. ¿Qué puede concluir al respecto?

**Modelo 7**

Definimos un modelo igual al **modelo 1** entrenando en el dataset de entrenamiento original y
usamos un modelo lineal robusto.

```{r warning=FALSE}
model_robusto <- rlm(
  peso ~ altura + edad + genero + dias_actividad_fisica_semanal + consumo_diario_alcohol, 
  data = original_train_set
)

coefficients_summary(model_robusto, show_tidy_sumamry = FALSE)

models <- list('Modelo 1' = model_1, 'Modelo Robusto' = model_robusto)
models %>% eval_models_summary(test_set,  metric_fn = rmse, include_r2 = FALSE)
models %>% eval_models_summary(test_set,  metric_fn = mae, include_r2  = FALSE)
```

Con RMSE los resultados son muy similares al punto anterior. En este caso el **Modelo Robusto** pierde 
con respecto al **Modelo 1**, inclusive por una diferencia mucho mas grande en test que el **Modelo 5**. El modelo 
robusto sufre del mismo problema que el **Modelo 5** donde tenemos un error en train mayor que test. Ahora
Midiendo con MAE los resultados se invierten y el **Modelo Robusto** gana por una diferencia poco significativa.

Como conclusión, Los modelos  **Modelo Robusto** y **Modelo 5** on son mejores que el **Modelo 1** sobre otro 
conjunto este conjunto de test. Por otro lado, los outliers presentes en el dataset original dificultan el
ajuste de los modelos en el entrenamiento. Por otro lado, no se aprecia una diferencia significativa en la performance
del **Modelo 5** y el **Modelo Robusto**.


**Evaluación de todos los modelos**

```{r warning=FALSE}
models <- list('Modelo 5' = model_5, 'Modelo Robusto' = model_robusto)

models %>% 
  eval_models_summary(test_set,  metric_fn = rmse) %>% 
  join_eval_summaries(rmse_eval_summary_result) %>%
  select(model, r_2_adjusted, train_error, test_error, error_diff)

models %>% 
  eval_models_summary(test_set,  metric_fn = mae) %>% 
  join_eval_summaries(mae_eval_summary_result) %>%
  select(model, r_2_adjusted, train_error, test_error, error_diff)
```


